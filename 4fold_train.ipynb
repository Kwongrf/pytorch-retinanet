{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start importing package...\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "# %load retinanet_train.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "print(\"Start importing package...\")\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import argparse\n",
    "import pdb\n",
    "import collections\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, models, transforms\n",
    "import torchvision\n",
    "\n",
    "import model\n",
    "import mymodel\n",
    "from anchors import Anchors\n",
    "import losses\n",
    "from dataloader import CocoDataset, CSVDataset, collater, Resizer, AspectRatioBasedSampler, Augmenter, UnNormalizer, Normalizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from mydataloader import MyDataset,MyAugmenter\n",
    "import coco_eval\n",
    "import csv_eval\n",
    "import visdom\n",
    "vis = visdom.Visdom(env='retinanet_seresnextTest')\n",
    "\n",
    "assert torch.__version__.split('.')[1] == '4'\n",
    "\n",
    "print('CUDA available: {}'.format(torch.cuda.is_available()))\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "#参数\n",
    "NAME=\"RSNA\"\n",
    "DATA_PATH = \"/data/krf/dataset\"\n",
    "CSV_TRAINS = [DATA_PATH + \"/test_csv_train0.csv\",DATA_PATH + \"/test_csv_train1.csv\",DATA_PATH + \"/test_csv_train2.csv\",DATA_PATH + \"/test_csv_train3.csv\"]\n",
    "CSV_VALS = [DATA_PATH + \"/test_csv_val0.csv\",DATA_PATH + \"/test_csv_val1.csv\",DATA_PATH + \"/test_csv_val2.csv\",DATA_PATH + \"/test_csv_val3.csv\"]\n",
    "CSV_CLASSES = DATA_PATH + \"/test_classes.csv\"\n",
    "DEPTH = 50\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE=2\n",
    "VAL_SIZE = 30\n",
    "#TRAIN_SIZE = 100\n",
    "#数据预处理\n",
    "import csv\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(DATA_PATH+\"/stage_1_train_labels.csv\") as f:\n",
    "#     reader = csv.reader(f)\n",
    "#     rows=[row for row in  reader]\n",
    "#     rows = rows[1:]\n",
    "#     random.shuffle(rows)\n",
    "#     for row in rows:\n",
    "#         row[0] = DATA_PATH+\"/stage_1_train_images/\"+row[0]+\".dcm\"\n",
    "#         if row[1] == '' and row[2] == '' and row[3] == '' and row[4] == '':\n",
    "#             row[5] = ''\n",
    "#         else:\n",
    "#             row[3] = str(float(row[1]) + float(row[3]))# x2 = x1 + w \n",
    "#             row[4] = str(float(row[2]) + float(row[4]))# y2 = y1 + h\n",
    "#     val_rows = rows[:VAL_SIZE]\n",
    "#     train_rows = rows[VAL_SIZE:]\n",
    "#     print(len(val_rows),len(train_rows))\n",
    "#     with open(CSV_TRAIN,'w') as f2:\n",
    "#         write = csv.writer(f2)\n",
    "#         write.writerows(train_rows)\n",
    "#         print(\"csv_train 写入完毕\")\n",
    "#     with open(CSV_VAL,'w') as f3:\n",
    "#         write = csv.writer(f3)\n",
    "#         write.writerows(val_rows)\n",
    "#         print(\"csv_val 写入完毕\")\n",
    "\n",
    "# with open(CSV_CLASSES,'w') as f:\n",
    "#     write = csv.writer(f)\n",
    "    \n",
    "#     row = ['0','0']\n",
    "#     write.writerow(row)\n",
    "#     row = ['1','1']\n",
    "#     write.writerow(row)\n",
    "#     row = ['2','2']\n",
    "#     write.writerow(row)\n",
    "#     print(\"csv_classes 写入完毕\")\n",
    "\n",
    "\n",
    "\n",
    "# # #每次跑这个函数之前需要先删除之前的\n",
    "\n",
    "# df = pd.read_csv(DATA_PATH+\"/stage_1_train_labels.csv\")\n",
    "# ddf = pd.read_csv(DATA_PATH+'/stage_1_detailed_class_info.csv')\n",
    "# train_images = os.listdir(DATA_PATH+\"/stage_1_train_images\")[:500]\n",
    "\n",
    "# random.shuffle(train_images)#打乱图片顺序\n",
    "# count = 0\n",
    "# pos_cnt_train = [0,0,0,0]\n",
    "# pos_cnt_val = [0,0,0,0]\n",
    "# class_dict = {'Normal':0,'Lung Opacity':1,'No Lung Opacity / Not Normal':2}\n",
    "# for img_name in tqdm(train_images):\n",
    "#     results = df[df['patientId']==img_name.split('.')[0]].values\n",
    "#     detail = ddf[df['patientId']==img_name.split('.')[0]].values\n",
    "#     for row in results:\n",
    "#         row[0] = DATA_PATH+\"/stage_1_train_images/\"+row[0]+\".dcm\"\n",
    "#         if row[5] == 1:\n",
    "#             pos_cnt_val[count % 4] += 1\n",
    "#         if row[1] >= 0 and row[1] <= 1024:\n",
    "#             row[3] = str(float(row[1]) + float(row[3]))# x2 = x1 + w \n",
    "#             row[4] = str(float(row[2]) + float(row[4]))# y2 = y1 + h\n",
    "#         else:\n",
    "#             row[1] = ''\n",
    "#             row[2] = ''\n",
    "#             row[3] = ''\n",
    "#             row[4] = ''\n",
    "#             row[5] = class_dict[detail[0,1]]\n",
    "#         with open(CSV_VALS[count % 4],'a') as f:\n",
    "#             write = csv.writer(f)\n",
    "#             write.writerow(row)\n",
    "#         for i in range(4):\n",
    "#             if count % 4 == i:\n",
    "#                 continue\n",
    "#             else:\n",
    "#                 with open(CSV_TRAINS[count % 4],'a') as f:\n",
    "#                     write = csv.writer(f)\n",
    "#                     write.writerow(row) \n",
    "#     count += 1\n",
    "# print(pos_cnt_train,pos_cnt_val)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Loading data...\")\n",
    "\n",
    "#%time\n",
    "#制作数据loader\n",
    "dataset_train = []\n",
    "dataset_val = []\n",
    "\n",
    "for i in range(4): \n",
    "    dataset_train.append(MyDataset(train_file=CSV_TRAINS[i], class_list=CSV_CLASSES, transform=transforms.Compose([Normalizer(), MyAugmenter(), Resizer()])))\n",
    "    dataset_val.append(MyDataset(train_file=CSV_VALS[i], class_list=CSV_CLASSES, transform=transforms.Compose([Normalizer(), Resizer()])))\n",
    "\n",
    "#每次的sampler的参数：来源、batchsize、是否抛弃最后一层？？？\n",
    "\n",
    "# num_workers 同时工作的组？collater:校验用的吧\n",
    "dataloader_train = []\n",
    "dataloader_val = []\n",
    "\n",
    "for i in range(4):\n",
    "    sampler = AspectRatioBasedSampler(dataset_train[i], batch_size=BATCH_SIZE, drop_last=False)\n",
    "    sampler_val = AspectRatioBasedSampler(dataset_val[i], batch_size=1, drop_last=False)\n",
    "    dataloader_train.append(DataLoader(dataset_train[i], num_workers=1, collate_fn=collater, batch_sampler=sampler))\n",
    "    dataloader_val.append(DataLoader(dataset_val[i], num_workers=1, collate_fn=collater, batch_sampler=sampler_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num training images: 300\n",
      "Num training images: 280\n"
     ]
    }
   ],
   "source": [
    "retinanets = []\n",
    "# Create the model\n",
    "# if DEPTH == 18:\n",
    "#     retinanet = model.resnet18(num_classes=dataset_train.num_classes(), pretrained=True)\n",
    "# elif DEPTH == 34:\n",
    "#     retinanet = model.resnet34(num_classes=dataset_train.num_classes(), pretrained=True)\n",
    "# elif DEPTH == 50:\n",
    "#     for i in range(4):\n",
    "#         retinanets.append(model.resnet50(num_classes=dataset_train[i].num_classes(), pretrained=True))\n",
    "# elif DEPTH == 101:\n",
    "#     for i in range(4):\n",
    "#         retinanets.append(model.resnet101(num_classes=dataset_train[i].num_classes(), pretrained=True)) \n",
    "# elif DEPTH == 152:\n",
    "#     for i in range(4):\n",
    "#         retinanets.append(model.resnet152(num_classes=dataset_train[i].num_classes(), pretrained=True))\n",
    "# else:\n",
    "#     raise ValueError('Unsupported model depth, must be one of 18, 34, 50, 101, 152')\n",
    "#retinanet = torch.load('weights/RSNA_retinanet_5.pt')\n",
    "for i in range(2):\n",
    "    retinanets.append(mymodel.se_resnext50_32x4d(num_classes=dataset_train[i].num_classes()))\n",
    "optimizer = []\n",
    "scheduler = []\n",
    "loss_hist = []\n",
    "classloss_hist = []\n",
    "regressloss_hist = []\n",
    "wholeclassloss_hist = []\n",
    "for i in range(2):\n",
    "    retinanets[i] = retinanets[i].cuda()\n",
    "    #变成并行\n",
    "    retinanets[i] = torch.nn.DataParallel(retinanets[i]).cuda()\n",
    "    #训练模式\n",
    "    retinanets[i].training = True\n",
    "    #学习率0.00001  \n",
    "    optimizer.append(optim.Adam(retinanets[i].parameters(), lr=1e-4))\n",
    "    #如果3个epoch损失没有减少则降低学习率\n",
    "    scheduler.append(optim.lr_scheduler.ReduceLROnPlateau(optimizer[i], patience=2, verbose=True))\n",
    "    # TODO 这是干什么 deque是为了高效实现插入和删除操作的双向列表，适合用于队列和栈：这里是定义了一个500的队列\n",
    "    loss_hist.append(collections.deque(maxlen=500))\n",
    "    classloss_hist.append(collections.deque(maxlen=500))\n",
    "    regressloss_hist.append(collections.deque(maxlen=500))\n",
    "    wholeclassloss_hist.append(collections.deque(maxlen=500))\n",
    "    print('Num training images: {}'.format(len(dataset_train[i])))\n",
    "# In[5]:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flip_x\n",
      "flip_x\n",
      "flip_x\n",
      "scale\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/krf/anaconda/anaconda3/lib/python3.5/site-packages/torch/nn/modules/upsampling.py:122: UserWarning: nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/data/krf/anaconda/anaconda3/lib/python3.5/site-packages/torch/nn/parallel/_functions.py:58: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Iteration: 0 | Classification loss: 0.12567 | Regression loss: 0.00000 | Whole Class loss: 1.13655 | Running loss: 1.26222\n",
      "shift\n",
      "shift\n",
      "Epoch: 0 | Iteration: 1 | Classification loss: 0.37343 | Regression loss: 0.26745 | Whole Class loss: 1.40960 | Running loss: 2.05048\n",
      "Epoch: 0 | Iteration: 2 | Classification loss: 0.28346 | Regression loss: 0.17830 | Whole Class loss: 1.27313 | Running loss: 1.73489\n",
      "shift\n",
      "Epoch: 0 | Iteration: 3 | Classification loss: 0.23187 | Regression loss: 0.13373 | Whole Class loss: 1.20608 | Running loss: 1.57168\n",
      "Epoch: 0 | Iteration: 4 | Classification loss: 0.19495 | Regression loss: 0.10698 | Whole Class loss: 1.17726 | Running loss: 1.47919\n",
      "shift\n",
      "Epoch: 0 | Iteration: 5 | Classification loss: 0.26068 | Regression loss: 0.18900 | Whole Class loss: 1.14315 | Running loss: 1.59282\n",
      "shift\n",
      "scale\n",
      "Epoch: 0 | Iteration: 6 | Classification loss: 0.22574 | Regression loss: 0.16200 | Whole Class loss: 1.16967 | Running loss: 1.55741\n",
      "Epoch: 0 | Iteration: 7 | Classification loss: 0.19886 | Regression loss: 0.14175 | Whole Class loss: 1.14302 | Running loss: 1.48362\n",
      "shift\n",
      "scale\n",
      "Epoch: 0 | Iteration: 8 | Classification loss: 0.17760 | Regression loss: 0.12600 | Whole Class loss: 1.13432 | Running loss: 1.43791\n",
      "Epoch: 0 | Iteration: 9 | Classification loss: 0.16043 | Regression loss: 0.11340 | Whole Class loss: 1.10671 | Running loss: 1.38054\n",
      "shift\n",
      "shift\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 10 | Classification loss: 0.19947 | Regression loss: 0.14975 | Whole Class loss: 1.11354 | Running loss: 1.46275\n",
      "shift\n",
      "shift\n",
      "shift\n",
      "Epoch: 0 | Iteration: 11 | Classification loss: 0.23529 | Regression loss: 0.17760 | Whole Class loss: 1.13001 | Running loss: 1.54290\n",
      "rotate\n",
      "Epoch: 0 | Iteration: 12 | Classification loss: 0.21752 | Regression loss: 0.16394 | Whole Class loss: 1.08218 | Running loss: 1.46364\n",
      "Epoch: 0 | Iteration: 13 | Classification loss: 0.20230 | Regression loss: 0.15223 | Whole Class loss: 1.12187 | Running loss: 1.47640\n",
      "scale\n",
      "scale\n",
      "Epoch: 0 | Iteration: 14 | Classification loss: 0.19016 | Regression loss: 0.14208 | Whole Class loss: 1.15660 | Running loss: 1.48883\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 15 | Classification loss: 0.17860 | Regression loss: 0.13320 | Whole Class loss: 1.13659 | Running loss: 1.44839\n",
      "shift\n",
      "Epoch: 0 | Iteration: 16 | Classification loss: 0.21086 | Regression loss: 0.15609 | Whole Class loss: 1.16336 | Running loss: 1.53031\n",
      "flip_x\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 17 | Classification loss: 0.19946 | Regression loss: 0.14742 | Whole Class loss: 1.12601 | Running loss: 1.47289\n",
      "shift\n",
      "Epoch: 0 | Iteration: 18 | Classification loss: 0.18922 | Regression loss: 0.13966 | Whole Class loss: 1.11561 | Running loss: 1.44450\n",
      "flip_x\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 19 | Classification loss: 0.20872 | Regression loss: 0.15833 | Whole Class loss: 1.11690 | Running loss: 1.48395\n",
      "Epoch: 0 | Iteration: 20 | Classification loss: 0.19911 | Regression loss: 0.15079 | Whole Class loss: 1.10850 | Running loss: 1.45840\n",
      "rotate\n",
      "Epoch: 0 | Iteration: 21 | Classification loss: 0.19053 | Regression loss: 0.14394 | Whole Class loss: 1.09105 | Running loss: 1.42552\n",
      "Epoch: 0 | Iteration: 22 | Classification loss: 0.18254 | Regression loss: 0.13768 | Whole Class loss: 1.11350 | Running loss: 1.43372\n",
      "noise\n",
      "Epoch: 0 | Iteration: 23 | Classification loss: 0.19924 | Regression loss: 0.15370 | Whole Class loss: 1.10918 | Running loss: 1.46212\n",
      "flip_x\n",
      "flip_x\n",
      "scale\n",
      "Epoch: 0 | Iteration: 24 | Classification loss: 0.19158 | Regression loss: 0.14755 | Whole Class loss: 1.08469 | Running loss: 1.42382\n",
      "Epoch: 0 | Iteration: 25 | Classification loss: 0.18454 | Regression loss: 0.14187 | Whole Class loss: 1.08984 | Running loss: 1.41626\n",
      "flip_x\n",
      "flip_x\n",
      "shift\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 26 | Classification loss: 0.17807 | Regression loss: 0.13662 | Whole Class loss: 1.09190 | Running loss: 1.40659\n",
      "rotate\n",
      "Epoch: 0 | Iteration: 27 | Classification loss: 0.17199 | Regression loss: 0.13174 | Whole Class loss: 1.07485 | Running loss: 1.37858\n",
      "shift\n",
      "Epoch: 0 | Iteration: 28 | Classification loss: 0.18589 | Regression loss: 0.14272 | Whole Class loss: 1.08841 | Running loss: 1.41702\n",
      "shift\n",
      "Epoch: 0 | Iteration: 29 | Classification loss: 0.19928 | Regression loss: 0.15549 | Whole Class loss: 1.09716 | Running loss: 1.45193\n",
      "shift\n",
      "rotate\n",
      "Epoch: 0 | Iteration: 30 | Classification loss: 0.19315 | Regression loss: 0.15048 | Whole Class loss: 1.09500 | Running loss: 1.43863\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 31 | Classification loss: 0.20476 | Regression loss: 0.15973 | Whole Class loss: 1.10842 | Running loss: 1.47290\n",
      "scale\n",
      "Epoch: 0 | Iteration: 32 | Classification loss: 0.19880 | Regression loss: 0.15489 | Whole Class loss: 1.09746 | Running loss: 1.45115\n",
      "Epoch: 0 | Iteration: 33 | Classification loss: 0.19322 | Regression loss: 0.15033 | Whole Class loss: 1.08923 | Running loss: 1.43278\n",
      "rotate\n",
      "Epoch: 0 | Iteration: 34 | Classification loss: 0.20429 | Regression loss: 0.16196 | Whole Class loss: 1.09908 | Running loss: 1.46533\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 35 | Classification loss: 0.19897 | Regression loss: 0.15746 | Whole Class loss: 1.09348 | Running loss: 1.44991\n",
      "flip_x\n",
      "rotate\n",
      "Epoch: 0 | Iteration: 36 | Classification loss: 0.19385 | Regression loss: 0.15321 | Whole Class loss: 1.08928 | Running loss: 1.43633\n",
      "Epoch: 0 | Iteration: 37 | Classification loss: 0.18898 | Regression loss: 0.14918 | Whole Class loss: 1.08026 | Running loss: 1.41842\n",
      "flip_x\n",
      "scale\n",
      "Epoch: 0 | Iteration: 38 | Classification loss: 0.18438 | Regression loss: 0.14535 | Whole Class loss: 1.07205 | Running loss: 1.40178\n",
      "Epoch: 0 | Iteration: 39 | Classification loss: 0.17995 | Regression loss: 0.14172 | Whole Class loss: 1.06642 | Running loss: 1.38809\n",
      "rotate\n",
      "shift\n",
      "Epoch: 0 | Iteration: 40 | Classification loss: 0.17571 | Regression loss: 0.13826 | Whole Class loss: 1.06666 | Running loss: 1.38063\n",
      "scale\n",
      "Epoch: 0 | Iteration: 41 | Classification loss: 0.17160 | Regression loss: 0.13497 | Whole Class loss: 1.06370 | Running loss: 1.37027\n",
      "shift\n",
      "flip_x\n",
      "shift\n",
      "Epoch: 0 | Iteration: 42 | Classification loss: 0.18189 | Regression loss: 0.14300 | Whole Class loss: 1.10225 | Running loss: 1.42713\n",
      "Epoch: 0 | Iteration: 43 | Classification loss: 0.19100 | Regression loss: 0.15160 | Whole Class loss: 1.11557 | Running loss: 1.45817\n",
      "Epoch: 0 | Iteration: 44 | Classification loss: 0.18685 | Regression loss: 0.14823 | Whole Class loss: 1.10636 | Running loss: 1.44144\n",
      "shift\n",
      "Epoch: 0 | Iteration: 45 | Classification loss: 0.19700 | Regression loss: 0.15645 | Whole Class loss: 1.13066 | Running loss: 1.48410\n",
      "scale\n",
      "Epoch: 0 | Iteration: 46 | Classification loss: 0.20760 | Regression loss: 0.16416 | Whole Class loss: 1.14588 | Running loss: 1.51764\n",
      "Epoch: 0 | Iteration: 47 | Classification loss: 0.20337 | Regression loss: 0.16074 | Whole Class loss: 1.13306 | Running loss: 1.49716\n",
      "flip_x\n",
      "flip_x\n",
      "shift\n",
      "Epoch: 0 | Iteration: 48 | Classification loss: 0.19929 | Regression loss: 0.15746 | Whole Class loss: 1.12574 | Running loss: 1.48249\n",
      "noise\n",
      "Epoch: 0 | Iteration: 49 | Classification loss: 0.19538 | Regression loss: 0.15431 | Whole Class loss: 1.12059 | Running loss: 1.47028\n",
      "shift\n",
      "Epoch: 0 | Iteration: 50 | Classification loss: 0.20281 | Regression loss: 0.16183 | Whole Class loss: 1.11624 | Running loss: 1.48088\n",
      "shift\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 51 | Classification loss: 0.19900 | Regression loss: 0.15872 | Whole Class loss: 1.10600 | Running loss: 1.46372\n",
      "rotate\n",
      "Epoch: 0 | Iteration: 52 | Classification loss: 0.21756 | Regression loss: 0.17549 | Whole Class loss: 1.12721 | Running loss: 1.52027\n",
      "scale\n",
      "Epoch: 0 | Iteration: 53 | Classification loss: 0.21364 | Regression loss: 0.17224 | Whole Class loss: 1.12690 | Running loss: 1.51279\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 54 | Classification loss: 0.20985 | Regression loss: 0.16911 | Whole Class loss: 1.13548 | Running loss: 1.51444\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 55 | Classification loss: 0.20618 | Regression loss: 0.16609 | Whole Class loss: 1.12942 | Running loss: 1.50169\n",
      "flip_x\n",
      "scale\n",
      "Epoch: 0 | Iteration: 56 | Classification loss: 0.21253 | Regression loss: 0.17228 | Whole Class loss: 1.13698 | Running loss: 1.52180\n",
      "noise\n",
      "Epoch: 0 | Iteration: 57 | Classification loss: 0.20897 | Regression loss: 0.16931 | Whole Class loss: 1.13269 | Running loss: 1.51098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Iteration: 58 | Classification loss: 0.20551 | Regression loss: 0.16644 | Whole Class loss: 1.12928 | Running loss: 1.50124\n",
      "noise\n",
      "Epoch: 0 | Iteration: 59 | Classification loss: 0.20222 | Regression loss: 0.16367 | Whole Class loss: 1.12649 | Running loss: 1.49238\n",
      "scale\n",
      "Epoch: 0 | Iteration: 60 | Classification loss: 0.19903 | Regression loss: 0.16099 | Whole Class loss: 1.12433 | Running loss: 1.48435\n",
      "noise\n",
      "Epoch: 0 | Iteration: 61 | Classification loss: 0.19587 | Regression loss: 0.15839 | Whole Class loss: 1.11831 | Running loss: 1.47257\n",
      "shift\n",
      "shift\n",
      "scale\n",
      "Epoch: 0 | Iteration: 62 | Classification loss: 0.20177 | Regression loss: 0.16390 | Whole Class loss: 1.11655 | Running loss: 1.48222\n",
      "Epoch: 0 | Iteration: 63 | Classification loss: 0.19867 | Regression loss: 0.16134 | Whole Class loss: 1.11142 | Running loss: 1.47143\n",
      "flip_x\n",
      "flip_x\n",
      "shift\n",
      "Epoch: 0 | Iteration: 64 | Classification loss: 0.19566 | Regression loss: 0.15886 | Whole Class loss: 1.10648 | Running loss: 1.46100\n",
      "scale\n",
      "Epoch: 0 | Iteration: 65 | Classification loss: 0.19273 | Regression loss: 0.15645 | Whole Class loss: 1.10000 | Running loss: 1.44917\n",
      "Epoch: 0 | Iteration: 66 | Classification loss: 0.19946 | Regression loss: 0.16130 | Whole Class loss: 1.12157 | Running loss: 1.48232\n",
      "noise\n",
      "Epoch: 0 | Iteration: 67 | Classification loss: 0.19654 | Regression loss: 0.15892 | Whole Class loss: 1.13232 | Running loss: 1.48779\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 68 | Classification loss: 0.19373 | Regression loss: 0.15662 | Whole Class loss: 1.13345 | Running loss: 1.48380\n",
      "Epoch: 0 | Iteration: 69 | Classification loss: 0.19098 | Regression loss: 0.15438 | Whole Class loss: 1.12728 | Running loss: 1.47264\n",
      "shift\n",
      "Epoch: 0 | Iteration: 70 | Classification loss: 0.18831 | Regression loss: 0.15221 | Whole Class loss: 1.12274 | Running loss: 1.46326\n",
      "scale\n",
      "Epoch: 0 | Iteration: 71 | Classification loss: 0.19411 | Regression loss: 0.15673 | Whole Class loss: 1.13580 | Running loss: 1.48664\n",
      "flip_x\n",
      "shift\n",
      "Epoch: 0 | Iteration: 72 | Classification loss: 0.19147 | Regression loss: 0.15459 | Whole Class loss: 1.13088 | Running loss: 1.47693\n",
      "scale\n",
      "Epoch: 0 | Iteration: 73 | Classification loss: 0.18890 | Regression loss: 0.15250 | Whole Class loss: 1.12713 | Running loss: 1.46853\n",
      "flip_x\n",
      "shift\n",
      "Epoch: 0 | Iteration: 74 | Classification loss: 0.18641 | Regression loss: 0.15046 | Whole Class loss: 1.12218 | Running loss: 1.45905\n",
      "Epoch: 0 | Iteration: 75 | Classification loss: 0.18397 | Regression loss: 0.14848 | Whole Class loss: 1.11725 | Running loss: 1.44970\n",
      "shift\n",
      "Epoch: 0 | Iteration: 76 | Classification loss: 0.19105 | Regression loss: 0.15321 | Whole Class loss: 1.12734 | Running loss: 1.47160\n",
      "noise\n",
      "scale\n",
      "Epoch: 0 | Iteration: 77 | Classification loss: 0.18864 | Regression loss: 0.15124 | Whole Class loss: 1.12370 | Running loss: 1.46359\n",
      "noise\n",
      "noise\n",
      "Epoch: 0 | Iteration: 78 | Classification loss: 0.18630 | Regression loss: 0.14933 | Whole Class loss: 1.12029 | Running loss: 1.45592\n",
      "Epoch: 0 | Iteration: 79 | Classification loss: 0.18402 | Regression loss: 0.14746 | Whole Class loss: 1.11562 | Running loss: 1.44710\n",
      "scale\n",
      "Epoch: 0 | Iteration: 80 | Classification loss: 0.18864 | Regression loss: 0.15204 | Whole Class loss: 1.12336 | Running loss: 1.46404\n",
      "flip_x\n",
      "noise\n",
      "Epoch: 0 | Iteration: 81 | Classification loss: 0.19314 | Regression loss: 0.15655 | Whole Class loss: 1.13335 | Running loss: 1.48303\n",
      "rotate\n",
      "Epoch: 0 | Iteration: 82 | Classification loss: 0.19088 | Regression loss: 0.15466 | Whole Class loss: 1.13136 | Running loss: 1.47690\n",
      "shift\n",
      "Epoch: 0 | Iteration: 83 | Classification loss: 0.18865 | Regression loss: 0.15282 | Whole Class loss: 1.12768 | Running loss: 1.46915\n",
      "shift\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 84 | Classification loss: 0.19647 | Regression loss: 0.15649 | Whole Class loss: 1.13254 | Running loss: 1.48550\n",
      "scale\n",
      "Epoch: 0 | Iteration: 85 | Classification loss: 0.19423 | Regression loss: 0.15467 | Whole Class loss: 1.12244 | Running loss: 1.47134\n",
      "flip_x\n",
      "shift\n",
      "Epoch: 0 | Iteration: 86 | Classification loss: 0.19897 | Regression loss: 0.15963 | Whole Class loss: 1.13098 | Running loss: 1.48958\n",
      "shift\n",
      "Epoch: 0 | Iteration: 87 | Classification loss: 0.20531 | Regression loss: 0.16399 | Whole Class loss: 1.14224 | Running loss: 1.51154\n",
      "Epoch: 0 | Iteration: 88 | Classification loss: 0.20308 | Regression loss: 0.16215 | Whole Class loss: 1.14485 | Running loss: 1.51008\n",
      "shift\n",
      "noise\n",
      "Epoch: 0 | Iteration: 89 | Classification loss: 0.20092 | Regression loss: 0.16035 | Whole Class loss: 1.13545 | Running loss: 1.49672\n",
      "Epoch: 0 | Iteration: 90 | Classification loss: 0.19882 | Regression loss: 0.15859 | Whole Class loss: 1.13493 | Running loss: 1.49234\n",
      "Epoch: 0 | Iteration: 91 | Classification loss: 0.19676 | Regression loss: 0.15686 | Whole Class loss: 1.13139 | Running loss: 1.48501\n",
      "noise\n",
      "Epoch: 0 | Iteration: 92 | Classification loss: 0.19474 | Regression loss: 0.15518 | Whole Class loss: 1.12330 | Running loss: 1.47322\n",
      "scale\n",
      "Epoch: 0 | Iteration: 93 | Classification loss: 0.19858 | Regression loss: 0.15901 | Whole Class loss: 1.12572 | Running loss: 1.48331\n",
      "shift\n",
      "Epoch: 0 | Iteration: 94 | Classification loss: 0.19658 | Regression loss: 0.15734 | Whole Class loss: 1.12542 | Running loss: 1.47934\n",
      "Epoch: 0 | Iteration: 95 | Classification loss: 0.19461 | Regression loss: 0.15570 | Whole Class loss: 1.12497 | Running loss: 1.47528\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 96 | Classification loss: 0.19825 | Regression loss: 0.15880 | Whole Class loss: 1.12580 | Running loss: 1.48285\n",
      "noise\n",
      "Epoch: 0 | Iteration: 97 | Classification loss: 0.19630 | Regression loss: 0.15718 | Whole Class loss: 1.12248 | Running loss: 1.47596\n",
      "Epoch: 0 | Iteration: 98 | Classification loss: 0.19439 | Regression loss: 0.15559 | Whole Class loss: 1.11925 | Running loss: 1.46923\n",
      "scale\n",
      "Epoch: 0 | Iteration: 99 | Classification loss: 0.19777 | Regression loss: 0.15895 | Whole Class loss: 1.11907 | Running loss: 1.47579\n",
      "Epoch: 0 | Iteration: 100 | Classification loss: 0.19589 | Regression loss: 0.15738 | Whole Class loss: 1.11650 | Running loss: 1.46977\n",
      "Epoch: 0 | Iteration: 101 | Classification loss: 0.19405 | Regression loss: 0.15584 | Whole Class loss: 1.11216 | Running loss: 1.46205\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 102 | Classification loss: 0.19225 | Regression loss: 0.15432 | Whole Class loss: 1.10833 | Running loss: 1.45490\n",
      "Epoch: 0 | Iteration: 103 | Classification loss: 0.19601 | Regression loss: 0.15766 | Whole Class loss: 1.11101 | Running loss: 1.46468\n",
      "shift\n",
      "Epoch: 0 | Iteration: 104 | Classification loss: 0.19960 | Regression loss: 0.16099 | Whole Class loss: 1.11601 | Running loss: 1.47659\n",
      "shift\n",
      "scale\n",
      "Epoch: 0 | Iteration: 105 | Classification loss: 0.19775 | Regression loss: 0.15947 | Whole Class loss: 1.11065 | Running loss: 1.46788\n",
      "Epoch: 0 | Iteration: 106 | Classification loss: 0.19594 | Regression loss: 0.15798 | Whole Class loss: 1.10544 | Running loss: 1.45936\n",
      "Epoch: 0 | Iteration: 107 | Classification loss: 0.19416 | Regression loss: 0.15652 | Whole Class loss: 1.10198 | Running loss: 1.45266\n",
      "shift\n",
      "Epoch: 0 | Iteration: 108 | Classification loss: 0.19754 | Regression loss: 0.15988 | Whole Class loss: 1.10600 | Running loss: 1.46342\n",
      "shift\n",
      "rotate\n",
      "Epoch: 0 | Iteration: 109 | Classification loss: 0.19576 | Regression loss: 0.15843 | Whole Class loss: 1.10015 | Running loss: 1.45434\n",
      "flip_x\n",
      "shift\n",
      "Epoch: 0 | Iteration: 110 | Classification loss: 0.19405 | Regression loss: 0.15700 | Whole Class loss: 1.09703 | Running loss: 1.44809\n",
      "Epoch: 0 | Iteration: 111 | Classification loss: 0.19234 | Regression loss: 0.15560 | Whole Class loss: 1.09354 | Running loss: 1.44149\n",
      "Epoch: 0 | Iteration: 112 | Classification loss: 0.19658 | Regression loss: 0.15906 | Whole Class loss: 1.11676 | Running loss: 1.47239\n",
      "shift\n",
      "Epoch: 0 | Iteration: 113 | Classification loss: 0.19992 | Regression loss: 0.16183 | Whole Class loss: 1.12474 | Running loss: 1.48649\n",
      "shift\n",
      "Epoch: 0 | Iteration: 114 | Classification loss: 0.19820 | Regression loss: 0.16042 | Whole Class loss: 1.12920 | Running loss: 1.48782\n",
      "scale\n",
      "noise\n",
      "Epoch: 0 | Iteration: 115 | Classification loss: 0.19653 | Regression loss: 0.15904 | Whole Class loss: 1.12419 | Running loss: 1.47976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shift\n",
      "Epoch: 0 | Iteration: 116 | Classification loss: 0.20003 | Regression loss: 0.16209 | Whole Class loss: 1.13288 | Running loss: 1.49499\n",
      "scale\n",
      "Epoch: 0 | Iteration: 117 | Classification loss: 0.19839 | Regression loss: 0.16071 | Whole Class loss: 1.12695 | Running loss: 1.48605\n",
      "shift\n",
      "shift\n",
      "Epoch: 0 | Iteration: 118 | Classification loss: 0.20183 | Regression loss: 0.16318 | Whole Class loss: 1.13746 | Running loss: 1.50247\n",
      "flip_x\n",
      "shift\n",
      "Epoch: 0 | Iteration: 119 | Classification loss: 0.20020 | Regression loss: 0.16182 | Whole Class loss: 1.13115 | Running loss: 1.49317\n",
      "noise\n",
      "Epoch: 0 | Iteration: 120 | Classification loss: 0.20316 | Regression loss: 0.16424 | Whole Class loss: 1.14947 | Running loss: 1.51688\n",
      "flip_x\n",
      "flip_x\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 121 | Classification loss: 0.20590 | Regression loss: 0.16675 | Whole Class loss: 1.15257 | Running loss: 1.52522\n",
      "shift\n",
      "Epoch: 0 | Iteration: 122 | Classification loss: 0.20434 | Regression loss: 0.16540 | Whole Class loss: 1.15256 | Running loss: 1.52230\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 123 | Classification loss: 0.20281 | Regression loss: 0.16406 | Whole Class loss: 1.15072 | Running loss: 1.51759\n",
      "flip_x\n",
      "scale\n",
      "Epoch: 0 | Iteration: 124 | Classification loss: 0.20129 | Regression loss: 0.16275 | Whole Class loss: 1.14434 | Running loss: 1.50838\n",
      "shift\n",
      "Epoch: 0 | Iteration: 125 | Classification loss: 0.19977 | Regression loss: 0.16146 | Whole Class loss: 1.14534 | Running loss: 1.50657\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 126 | Classification loss: 0.19827 | Regression loss: 0.16019 | Whole Class loss: 1.14021 | Running loss: 1.49867\n",
      "shift\n",
      "shift\n",
      "Epoch: 0 | Iteration: 127 | Classification loss: 0.20887 | Regression loss: 0.16682 | Whole Class loss: 1.15213 | Running loss: 1.52782\n",
      "Epoch: 0 | Iteration: 128 | Classification loss: 0.20732 | Regression loss: 0.16553 | Whole Class loss: 1.15048 | Running loss: 1.52332\n",
      "flip_x\n",
      "shift\n",
      "Epoch: 0 | Iteration: 129 | Classification loss: 0.21028 | Regression loss: 0.16848 | Whole Class loss: 1.15046 | Running loss: 1.52921\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 130 | Classification loss: 0.20873 | Regression loss: 0.16719 | Whole Class loss: 1.14784 | Running loss: 1.52376\n",
      "scale\n",
      "Epoch: 0 | Iteration: 131 | Classification loss: 0.20720 | Regression loss: 0.16593 | Whole Class loss: 1.14653 | Running loss: 1.51966\n",
      "Epoch: 0 | Iteration: 132 | Classification loss: 0.20569 | Regression loss: 0.16468 | Whole Class loss: 1.14344 | Running loss: 1.51381\n",
      "Epoch: 0 | Iteration: 133 | Classification loss: 0.20827 | Regression loss: 0.16710 | Whole Class loss: 1.14569 | Running loss: 1.52107\n",
      "shift\n",
      "flip_x\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 134 | Classification loss: 0.20678 | Regression loss: 0.16586 | Whole Class loss: 1.14312 | Running loss: 1.51576\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 135 | Classification loss: 0.20959 | Regression loss: 0.16849 | Whole Class loss: 1.14632 | Running loss: 1.52441\n",
      "shift\n",
      "Epoch: 0 | Iteration: 136 | Classification loss: 0.20810 | Regression loss: 0.16726 | Whole Class loss: 1.14424 | Running loss: 1.51961\n",
      "shift\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 137 | Classification loss: 0.21060 | Regression loss: 0.16977 | Whole Class loss: 1.14521 | Running loss: 1.52558\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 138 | Classification loss: 0.20912 | Regression loss: 0.16855 | Whole Class loss: 1.14226 | Running loss: 1.51993\n",
      "rotate\n",
      "shift\n",
      "Epoch: 0 | Iteration: 139 | Classification loss: 0.21340 | Regression loss: 0.17057 | Whole Class loss: 1.14214 | Running loss: 1.52611\n",
      "shift\n",
      "Epoch: 0 | Iteration: 140 | Classification loss: 0.21193 | Regression loss: 0.16936 | Whole Class loss: 1.13957 | Running loss: 1.52086\n",
      "rotate\n",
      "Epoch: 0 | Iteration: 141 | Classification loss: 0.21425 | Regression loss: 0.17173 | Whole Class loss: 1.13947 | Running loss: 1.52544\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 142 | Classification loss: 0.21665 | Regression loss: 0.17413 | Whole Class loss: 1.14028 | Running loss: 1.53106\n",
      "Epoch: 0 | Iteration: 143 | Classification loss: 0.21521 | Regression loss: 0.17292 | Whole Class loss: 1.13816 | Running loss: 1.52629\n",
      "scale\n",
      "Epoch: 0 | Iteration: 144 | Classification loss: 0.21741 | Regression loss: 0.17499 | Whole Class loss: 1.13882 | Running loss: 1.53122\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 145 | Classification loss: 0.21608 | Regression loss: 0.17379 | Whole Class loss: 1.13681 | Running loss: 1.52669\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 146 | Classification loss: 0.21849 | Regression loss: 0.17652 | Whole Class loss: 1.14063 | Running loss: 1.53564\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 147 | Classification loss: 0.22049 | Regression loss: 0.17959 | Whole Class loss: 1.14328 | Running loss: 1.54336\n",
      "noise\n",
      "Epoch: 0 | Iteration: 148 | Classification loss: 0.22306 | Regression loss: 0.18243 | Whole Class loss: 1.14583 | Running loss: 1.55133\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 149 | Classification loss: 0.22195 | Regression loss: 0.18122 | Whole Class loss: 1.14414 | Running loss: 1.54731\n",
      "Evaluating dataset\n",
      "300/300\n",
      "mAP:\n",
      "0: 0.0\n",
      "1: 0.0\n",
      "2: 0.0\n",
      "flip_x\n",
      "flip_x\n",
      "flip_x\n",
      "scale\n",
      "Epoch: 0 | Iteration: 0 | Classification loss: 0.12567 | Regression loss: 0.00000 | Whole Class loss: 1.10138 | Running loss: 1.22705\n",
      "Epoch: 0 | Iteration: 1 | Classification loss: 0.11621 | Regression loss: 0.00000 | Whole Class loss: 0.94791 | Running loss: 1.06413\n",
      "shift\n",
      "shift\n",
      "Epoch: 0 | Iteration: 2 | Classification loss: 0.10883 | Regression loss: 0.00000 | Whole Class loss: 1.09302 | Running loss: 1.20185\n",
      "shift\n",
      "Epoch: 0 | Iteration: 3 | Classification loss: 0.24002 | Regression loss: 0.14161 | Whole Class loss: 1.38279 | Running loss: 1.76442\n",
      "Epoch: 0 | Iteration: 4 | Classification loss: 0.19890 | Regression loss: 0.11328 | Whole Class loss: 1.15321 | Running loss: 1.46539\n",
      "shift\n",
      "Epoch: 0 | Iteration: 5 | Classification loss: 0.26504 | Regression loss: 0.17972 | Whole Class loss: 1.15454 | Running loss: 1.59929\n",
      "shift\n",
      "scale\n",
      "Epoch: 0 | Iteration: 6 | Classification loss: 0.22940 | Regression loss: 0.15404 | Whole Class loss: 1.16441 | Running loss: 1.54786\n",
      "Epoch: 0 | Iteration: 7 | Classification loss: 0.34671 | Regression loss: 0.27303 | Whole Class loss: 1.23117 | Running loss: 1.85090\n",
      "shift\n",
      "scale\n",
      "Epoch: 0 | Iteration: 8 | Classification loss: 0.37426 | Regression loss: 0.30370 | Whole Class loss: 1.30656 | Running loss: 1.98452\n",
      "Epoch: 0 | Iteration: 9 | Classification loss: 0.33818 | Regression loss: 0.27333 | Whole Class loss: 1.34982 | Running loss: 1.96133\n",
      "shift\n",
      "shift\n",
      "flip_x\n",
      "shift\n",
      "Epoch: 0 | Iteration: 10 | Classification loss: 0.30910 | Regression loss: 0.24848 | Whole Class loss: 1.33371 | Running loss: 1.89129\n",
      "shift\n",
      "shift\n",
      "Epoch: 0 | Iteration: 11 | Classification loss: 0.28463 | Regression loss: 0.22777 | Whole Class loss: 1.33320 | Running loss: 1.84561\n",
      "rotate\n",
      "Epoch: 0 | Iteration: 12 | Classification loss: 0.26361 | Regression loss: 0.21025 | Whole Class loss: 1.31640 | Running loss: 1.79026\n",
      "Epoch: 0 | Iteration: 13 | Classification loss: 0.24547 | Regression loss: 0.19524 | Whole Class loss: 1.30055 | Running loss: 1.74126\n",
      "scale\n",
      "scale\n",
      "Epoch: 0 | Iteration: 14 | Classification loss: 0.23043 | Regression loss: 0.18222 | Whole Class loss: 1.28613 | Running loss: 1.69879\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 15 | Classification loss: 0.21643 | Regression loss: 0.17083 | Whole Class loss: 1.26745 | Running loss: 1.65471\n",
      "shift\n",
      "Epoch: 0 | Iteration: 16 | Classification loss: 0.20406 | Regression loss: 0.16078 | Whole Class loss: 1.25198 | Running loss: 1.61682\n",
      "flip_x\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 17 | Classification loss: 0.23481 | Regression loss: 0.18214 | Whole Class loss: 1.25788 | Running loss: 1.67484\n",
      "shift\n",
      "Epoch: 0 | Iteration: 18 | Classification loss: 0.22267 | Regression loss: 0.17256 | Whole Class loss: 1.25076 | Running loss: 1.64599\n",
      "flip_x\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 19 | Classification loss: 0.21171 | Regression loss: 0.16393 | Whole Class loss: 1.23469 | Running loss: 1.61033\n",
      "Epoch: 0 | Iteration: 20 | Classification loss: 0.23023 | Regression loss: 0.18090 | Whole Class loss: 1.23209 | Running loss: 1.64322\n",
      "rotate\n",
      "Epoch: 0 | Iteration: 21 | Classification loss: 0.24901 | Regression loss: 0.19659 | Whole Class loss: 1.23759 | Running loss: 1.68318\n",
      "Epoch: 0 | Iteration: 22 | Classification loss: 0.23839 | Regression loss: 0.18804 | Whole Class loss: 1.21208 | Running loss: 1.63852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noise\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 23 | Classification loss: 0.26229 | Regression loss: 0.20387 | Whole Class loss: 1.21101 | Running loss: 1.67716\n",
      "flip_x\n",
      "scale\n",
      "Epoch: 0 | Iteration: 24 | Classification loss: 0.25211 | Regression loss: 0.19572 | Whole Class loss: 1.18660 | Running loss: 1.63442\n",
      "Epoch: 0 | Iteration: 25 | Classification loss: 0.26643 | Regression loss: 0.20756 | Whole Class loss: 1.21196 | Running loss: 1.68595\n",
      "flip_x\n",
      "flip_x\n",
      "shift\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 26 | Classification loss: 0.25733 | Regression loss: 0.19987 | Whole Class loss: 1.21047 | Running loss: 1.66767\n",
      "rotate\n",
      "Epoch: 0 | Iteration: 27 | Classification loss: 0.24893 | Regression loss: 0.19273 | Whole Class loss: 1.19605 | Running loss: 1.63772\n",
      "shift\n",
      "Epoch: 0 | Iteration: 28 | Classification loss: 0.24141 | Regression loss: 0.18609 | Whole Class loss: 1.18740 | Running loss: 1.61489\n",
      "shift\n",
      "shift\n",
      "rotate\n",
      "Epoch: 0 | Iteration: 29 | Classification loss: 0.25248 | Regression loss: 0.19720 | Whole Class loss: 1.20120 | Running loss: 1.65088\n",
      "Epoch: 0 | Iteration: 30 | Classification loss: 0.24484 | Regression loss: 0.19084 | Whole Class loss: 1.19977 | Running loss: 1.63545\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 31 | Classification loss: 0.25538 | Regression loss: 0.20229 | Whole Class loss: 1.19873 | Running loss: 1.65641\n",
      "scale\n",
      "Epoch: 0 | Iteration: 32 | Classification loss: 0.28267 | Regression loss: 0.22775 | Whole Class loss: 1.21598 | Running loss: 1.72640\n",
      "Epoch: 0 | Iteration: 33 | Classification loss: 0.27489 | Regression loss: 0.22105 | Whole Class loss: 1.20819 | Running loss: 1.70413\n",
      "rotate\n",
      "Epoch: 0 | Iteration: 34 | Classification loss: 0.26755 | Regression loss: 0.21474 | Whole Class loss: 1.19852 | Running loss: 1.68080\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 35 | Classification loss: 0.26091 | Regression loss: 0.20877 | Whole Class loss: 1.19293 | Running loss: 1.66261\n",
      "flip_x\n",
      "rotate\n",
      "Epoch: 0 | Iteration: 36 | Classification loss: 0.26947 | Regression loss: 0.21708 | Whole Class loss: 1.19593 | Running loss: 1.68248\n",
      "Epoch: 0 | Iteration: 37 | Classification loss: 0.26276 | Regression loss: 0.21137 | Whole Class loss: 1.18842 | Running loss: 1.66255\n",
      "flip_x\n",
      "scale\n",
      "Epoch: 0 | Iteration: 38 | Classification loss: 0.27115 | Regression loss: 0.22123 | Whole Class loss: 1.18370 | Running loss: 1.67608\n",
      "Epoch: 0 | Iteration: 39 | Classification loss: 0.27870 | Regression loss: 0.22884 | Whole Class loss: 1.18964 | Running loss: 1.69718\n",
      "rotate\n",
      "shift\n",
      "scale\n",
      "Epoch: 0 | Iteration: 40 | Classification loss: 0.27239 | Regression loss: 0.22326 | Whole Class loss: 1.18096 | Running loss: 1.67660\n",
      "Epoch: 0 | Iteration: 41 | Classification loss: 0.26617 | Regression loss: 0.21794 | Whole Class loss: 1.17358 | Running loss: 1.65770\n",
      "shift\n",
      "flip_x\n",
      "shift\n",
      "Epoch: 0 | Iteration: 42 | Classification loss: 0.27462 | Regression loss: 0.22491 | Whole Class loss: 1.18019 | Running loss: 1.67972\n",
      "Epoch: 0 | Iteration: 43 | Classification loss: 0.26863 | Regression loss: 0.21980 | Whole Class loss: 1.17950 | Running loss: 1.66793\n",
      "Epoch: 0 | Iteration: 44 | Classification loss: 0.26286 | Regression loss: 0.21492 | Whole Class loss: 1.17921 | Running loss: 1.65699\n",
      "shift\n",
      "Epoch: 0 | Iteration: 45 | Classification loss: 0.25735 | Regression loss: 0.21024 | Whole Class loss: 1.16595 | Running loss: 1.63355\n",
      "scale\n",
      "Epoch: 0 | Iteration: 46 | Classification loss: 0.25210 | Regression loss: 0.20577 | Whole Class loss: 1.15526 | Running loss: 1.61313\n",
      "Epoch: 0 | Iteration: 47 | Classification loss: 0.24704 | Regression loss: 0.20148 | Whole Class loss: 1.14421 | Running loss: 1.59273\n",
      "flip_x\n",
      "flip_x\n",
      "shift\n",
      "noise\n",
      "Epoch: 0 | Iteration: 48 | Classification loss: 0.24219 | Regression loss: 0.19737 | Whole Class loss: 1.15480 | Running loss: 1.59436\n",
      "Epoch: 0 | Iteration: 49 | Classification loss: 0.23748 | Regression loss: 0.19342 | Whole Class loss: 1.15367 | Running loss: 1.58458\n",
      "shift\n",
      "Epoch: 0 | Iteration: 50 | Classification loss: 0.23308 | Regression loss: 0.18963 | Whole Class loss: 1.14577 | Running loss: 1.56848\n",
      "shift\n",
      "flip_x\n",
      "rotate\n",
      "Epoch: 0 | Iteration: 51 | Classification loss: 0.22873 | Regression loss: 0.18599 | Whole Class loss: 1.13705 | Running loss: 1.55177\n",
      "Epoch: 0 | Iteration: 52 | Classification loss: 0.23553 | Regression loss: 0.19227 | Whole Class loss: 1.14615 | Running loss: 1.57395\n",
      "scale\n",
      "Epoch: 0 | Iteration: 53 | Classification loss: 0.23131 | Regression loss: 0.18871 | Whole Class loss: 1.14832 | Running loss: 1.56834\n",
      "flip_x\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 54 | Classification loss: 0.23799 | Regression loss: 0.19443 | Whole Class loss: 1.15912 | Running loss: 1.59154\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 55 | Classification loss: 0.24548 | Regression loss: 0.20078 | Whole Class loss: 1.16522 | Running loss: 1.61148\n",
      "scale\n",
      "Epoch: 0 | Iteration: 56 | Classification loss: 0.25141 | Regression loss: 0.20662 | Whole Class loss: 1.17151 | Running loss: 1.62955\n",
      "Epoch: 0 | Iteration: 57 | Classification loss: 0.24719 | Regression loss: 0.20306 | Whole Class loss: 1.16920 | Running loss: 1.61945\n",
      "noise\n",
      "Epoch: 0 | Iteration: 58 | Classification loss: 0.24311 | Regression loss: 0.19962 | Whole Class loss: 1.16272 | Running loss: 1.60545\n",
      "noise\n",
      "Epoch: 0 | Iteration: 59 | Classification loss: 0.24893 | Regression loss: 0.20569 | Whole Class loss: 1.16090 | Running loss: 1.61551\n",
      "scale\n",
      "Epoch: 0 | Iteration: 60 | Classification loss: 0.24506 | Regression loss: 0.20231 | Whole Class loss: 1.15757 | Running loss: 1.60495\n",
      "noise\n",
      "Epoch: 0 | Iteration: 61 | Classification loss: 0.24126 | Regression loss: 0.19905 | Whole Class loss: 1.16226 | Running loss: 1.60257\n",
      "shift\n",
      "shift\n",
      "scale\n",
      "Epoch: 0 | Iteration: 62 | Classification loss: 0.23767 | Regression loss: 0.19589 | Whole Class loss: 1.15971 | Running loss: 1.59327\n",
      "Epoch: 0 | Iteration: 63 | Classification loss: 0.23411 | Regression loss: 0.19283 | Whole Class loss: 1.15496 | Running loss: 1.58190\n",
      "flip_x\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 64 | Classification loss: 0.23066 | Regression loss: 0.18986 | Whole Class loss: 1.15117 | Running loss: 1.57169\n",
      "shift\n",
      "scale\n",
      "Epoch: 0 | Iteration: 65 | Classification loss: 0.22729 | Regression loss: 0.18699 | Whole Class loss: 1.14650 | Running loss: 1.56078\n",
      "Epoch: 0 | Iteration: 66 | Classification loss: 0.22402 | Regression loss: 0.18420 | Whole Class loss: 1.14260 | Running loss: 1.55081\n",
      "noise\n",
      "Epoch: 0 | Iteration: 67 | Classification loss: 0.22081 | Regression loss: 0.18149 | Whole Class loss: 1.13836 | Running loss: 1.54066\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 68 | Classification loss: 0.21776 | Regression loss: 0.17886 | Whole Class loss: 1.13599 | Running loss: 1.53261\n",
      "shift\n",
      "Epoch: 0 | Iteration: 69 | Classification loss: 0.21469 | Regression loss: 0.17630 | Whole Class loss: 1.13139 | Running loss: 1.52239\n",
      "scale\n",
      "Epoch: 0 | Iteration: 70 | Classification loss: 0.21170 | Regression loss: 0.17382 | Whole Class loss: 1.12604 | Running loss: 1.51156\n",
      "Epoch: 0 | Iteration: 71 | Classification loss: 0.20878 | Regression loss: 0.17140 | Whole Class loss: 1.12101 | Running loss: 1.50120\n",
      "flip_x\n",
      "shift\n",
      "scale\n",
      "Epoch: 0 | Iteration: 72 | Classification loss: 0.20594 | Regression loss: 0.16906 | Whole Class loss: 1.11479 | Running loss: 1.48979\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 73 | Classification loss: 0.20318 | Regression loss: 0.16677 | Whole Class loss: 1.12310 | Running loss: 1.49305\n",
      "shift\n",
      "shift\n",
      "Epoch: 0 | Iteration: 74 | Classification loss: 0.20048 | Regression loss: 0.16455 | Whole Class loss: 1.12118 | Running loss: 1.48621\n",
      "noise\n",
      "Epoch: 0 | Iteration: 75 | Classification loss: 0.19785 | Regression loss: 0.16238 | Whole Class loss: 1.11726 | Running loss: 1.47749\n",
      "Epoch: 0 | Iteration: 76 | Classification loss: 0.20567 | Regression loss: 0.17060 | Whole Class loss: 1.13823 | Running loss: 1.51450\n",
      "scale\n",
      "Epoch: 0 | Iteration: 77 | Classification loss: 0.21195 | Regression loss: 0.17691 | Whole Class loss: 1.15105 | Running loss: 1.53991\n",
      "noise\n",
      "noise\n",
      "Epoch: 0 | Iteration: 78 | Classification loss: 0.20930 | Regression loss: 0.17467 | Whole Class loss: 1.14520 | Running loss: 1.52918\n",
      "scale\n",
      "Epoch: 0 | Iteration: 79 | Classification loss: 0.20672 | Regression loss: 0.17249 | Whole Class loss: 1.14457 | Running loss: 1.52378\n",
      "Epoch: 0 | Iteration: 80 | Classification loss: 0.20417 | Regression loss: 0.17036 | Whole Class loss: 1.13606 | Running loss: 1.51059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flip_x\n",
      "noise\n",
      "Epoch: 0 | Iteration: 81 | Classification loss: 0.20170 | Regression loss: 0.16828 | Whole Class loss: 1.13213 | Running loss: 1.50211\n",
      "rotate\n",
      "shift\n",
      "Epoch: 0 | Iteration: 82 | Classification loss: 0.20706 | Regression loss: 0.17249 | Whole Class loss: 1.13589 | Running loss: 1.51544\n",
      "shift\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 83 | Classification loss: 0.20460 | Regression loss: 0.17044 | Whole Class loss: 1.13168 | Running loss: 1.50672\n",
      "scale\n",
      "Epoch: 0 | Iteration: 84 | Classification loss: 0.20946 | Regression loss: 0.17407 | Whole Class loss: 1.14072 | Running loss: 1.52426\n",
      "Epoch: 0 | Iteration: 85 | Classification loss: 0.20704 | Regression loss: 0.17205 | Whole Class loss: 1.13251 | Running loss: 1.51160\n",
      "flip_x\n",
      "shift\n",
      "shift\n",
      "Epoch: 0 | Iteration: 86 | Classification loss: 0.20470 | Regression loss: 0.17007 | Whole Class loss: 1.13954 | Running loss: 1.51431\n",
      "shift\n",
      "Epoch: 0 | Iteration: 87 | Classification loss: 0.20241 | Regression loss: 0.16814 | Whole Class loss: 1.13309 | Running loss: 1.50364\n",
      "noise\n",
      "Epoch: 0 | Iteration: 88 | Classification loss: 0.20736 | Regression loss: 0.17120 | Whole Class loss: 1.14469 | Running loss: 1.52325\n",
      "Epoch: 0 | Iteration: 89 | Classification loss: 0.20510 | Regression loss: 0.16930 | Whole Class loss: 1.14066 | Running loss: 1.51506\n",
      "Epoch: 0 | Iteration: 90 | Classification loss: 0.20294 | Regression loss: 0.16744 | Whole Class loss: 1.13672 | Running loss: 1.50709\n",
      "noise\n",
      "Epoch: 0 | Iteration: 91 | Classification loss: 0.20717 | Regression loss: 0.17202 | Whole Class loss: 1.14170 | Running loss: 1.52089\n",
      "Epoch: 0 | Iteration: 92 | Classification loss: 0.20500 | Regression loss: 0.17017 | Whole Class loss: 1.14032 | Running loss: 1.51550\n",
      "scale\n",
      "Epoch: 0 | Iteration: 93 | Classification loss: 0.20292 | Regression loss: 0.16836 | Whole Class loss: 1.13929 | Running loss: 1.51057\n",
      "shift\n",
      "Epoch: 0 | Iteration: 94 | Classification loss: 0.20719 | Regression loss: 0.17251 | Whole Class loss: 1.14385 | Running loss: 1.52355\n",
      "Epoch: 0 | Iteration: 95 | Classification loss: 0.20511 | Regression loss: 0.17072 | Whole Class loss: 1.14188 | Running loss: 1.51770\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 96 | Classification loss: 0.20308 | Regression loss: 0.16896 | Whole Class loss: 1.13832 | Running loss: 1.51036\n",
      "noise\n",
      "Epoch: 0 | Iteration: 97 | Classification loss: 0.20108 | Regression loss: 0.16723 | Whole Class loss: 1.13424 | Running loss: 1.50255\n",
      "Epoch: 0 | Iteration: 98 | Classification loss: 0.19913 | Regression loss: 0.16554 | Whole Class loss: 1.13172 | Running loss: 1.49639\n",
      "scale\n",
      "Epoch: 0 | Iteration: 99 | Classification loss: 0.19724 | Regression loss: 0.16389 | Whole Class loss: 1.12988 | Running loss: 1.49101\n",
      "Epoch: 0 | Iteration: 100 | Classification loss: 0.20214 | Regression loss: 0.16804 | Whole Class loss: 1.13365 | Running loss: 1.50383\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 101 | Classification loss: 0.20023 | Regression loss: 0.16639 | Whole Class loss: 1.13016 | Running loss: 1.49679\n",
      "Epoch: 0 | Iteration: 102 | Classification loss: 0.19837 | Regression loss: 0.16478 | Whole Class loss: 1.12718 | Running loss: 1.49033\n",
      "shift\n",
      "Epoch: 0 | Iteration: 103 | Classification loss: 0.19653 | Regression loss: 0.16319 | Whole Class loss: 1.12469 | Running loss: 1.48441\n",
      "shift\n",
      "Epoch: 0 | Iteration: 104 | Classification loss: 0.20014 | Regression loss: 0.16613 | Whole Class loss: 1.13064 | Running loss: 1.49691\n",
      "scale\n",
      "Epoch: 0 | Iteration: 105 | Classification loss: 0.19832 | Regression loss: 0.16456 | Whole Class loss: 1.12726 | Running loss: 1.49014\n",
      "Epoch: 0 | Iteration: 106 | Classification loss: 0.20208 | Regression loss: 0.16788 | Whole Class loss: 1.13242 | Running loss: 1.50237\n",
      "Epoch: 0 | Iteration: 107 | Classification loss: 0.20029 | Regression loss: 0.16632 | Whole Class loss: 1.13041 | Running loss: 1.49702\n",
      "shift\n",
      "shift\n",
      "rotate\n",
      "Epoch: 0 | Iteration: 108 | Classification loss: 0.19852 | Regression loss: 0.16480 | Whole Class loss: 1.12620 | Running loss: 1.48951\n",
      "Epoch: 0 | Iteration: 109 | Classification loss: 0.19678 | Regression loss: 0.16330 | Whole Class loss: 1.12276 | Running loss: 1.48284\n",
      "flip_x\n",
      "shift\n",
      "Epoch: 0 | Iteration: 110 | Classification loss: 0.19510 | Regression loss: 0.16183 | Whole Class loss: 1.12420 | Running loss: 1.48113\n",
      "Epoch: 0 | Iteration: 111 | Classification loss: 0.19842 | Regression loss: 0.16469 | Whole Class loss: 1.12741 | Running loss: 1.49053\n",
      "shift\n",
      "shift\n",
      "Epoch: 0 | Iteration: 112 | Classification loss: 0.20188 | Regression loss: 0.16806 | Whole Class loss: 1.13153 | Running loss: 1.50147\n",
      "scale\n",
      "Epoch: 0 | Iteration: 113 | Classification loss: 0.21037 | Regression loss: 0.17574 | Whole Class loss: 1.14524 | Running loss: 1.53135\n",
      "Epoch: 0 | Iteration: 114 | Classification loss: 0.21866 | Regression loss: 0.18208 | Whole Class loss: 1.15669 | Running loss: 1.55744\n",
      "noise\n",
      "Epoch: 0 | Iteration: 115 | Classification loss: 0.21684 | Regression loss: 0.18051 | Whole Class loss: 1.15313 | Running loss: 1.55048\n",
      "shift\n",
      "scale\n",
      "Epoch: 0 | Iteration: 116 | Classification loss: 0.21509 | Regression loss: 0.17897 | Whole Class loss: 1.15109 | Running loss: 1.54514\n",
      "shift\n",
      "shift\n",
      "Epoch: 0 | Iteration: 117 | Classification loss: 0.21334 | Regression loss: 0.17745 | Whole Class loss: 1.14819 | Running loss: 1.53899\n",
      "flip_x\n",
      "shift\n",
      "Epoch: 0 | Iteration: 118 | Classification loss: 0.21163 | Regression loss: 0.17596 | Whole Class loss: 1.14537 | Running loss: 1.53297\n",
      "noise\n",
      "Epoch: 0 | Iteration: 119 | Classification loss: 0.20994 | Regression loss: 0.17450 | Whole Class loss: 1.14234 | Running loss: 1.52677\n",
      "Epoch: 0 | Iteration: 120 | Classification loss: 0.20828 | Regression loss: 0.17305 | Whole Class loss: 1.13968 | Running loss: 1.52102\n",
      "flip_x\n",
      "flip_x\n",
      "flip_x\n",
      "shift\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 121 | Classification loss: 0.20666 | Regression loss: 0.17164 | Whole Class loss: 1.13767 | Running loss: 1.51596\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 122 | Classification loss: 0.20504 | Regression loss: 0.17024 | Whole Class loss: 1.13451 | Running loss: 1.50979\n",
      "scale\n",
      "Epoch: 0 | Iteration: 123 | Classification loss: 0.21093 | Regression loss: 0.17356 | Whole Class loss: 1.14113 | Running loss: 1.52562\n",
      "Epoch: 0 | Iteration: 124 | Classification loss: 0.20930 | Regression loss: 0.17217 | Whole Class loss: 1.13842 | Running loss: 1.51988\n",
      "shift\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 125 | Classification loss: 0.20768 | Regression loss: 0.17080 | Whole Class loss: 1.13570 | Running loss: 1.51419\n",
      "shift\n",
      "Epoch: 0 | Iteration: 126 | Classification loss: 0.21059 | Regression loss: 0.17401 | Whole Class loss: 1.13846 | Running loss: 1.52307\n",
      "shift\n",
      "Epoch: 0 | Iteration: 127 | Classification loss: 0.21357 | Regression loss: 0.17700 | Whole Class loss: 1.14446 | Running loss: 1.53503\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 128 | Classification loss: 0.21196 | Regression loss: 0.17563 | Whole Class loss: 1.14218 | Running loss: 1.52977\n",
      "shift\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 129 | Classification loss: 0.21038 | Regression loss: 0.17428 | Whole Class loss: 1.13789 | Running loss: 1.52255\n",
      "scale\n",
      "Epoch: 0 | Iteration: 130 | Classification loss: 0.20883 | Regression loss: 0.17295 | Whole Class loss: 1.13377 | Running loss: 1.51555\n",
      "Epoch: 0 | Iteration: 131 | Classification loss: 0.21199 | Regression loss: 0.17605 | Whole Class loss: 1.14294 | Running loss: 1.53097\n",
      "Epoch: 0 | Iteration: 132 | Classification loss: 0.21044 | Regression loss: 0.17472 | Whole Class loss: 1.13987 | Running loss: 1.52503\n",
      "shift\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 133 | Classification loss: 0.21312 | Regression loss: 0.17719 | Whole Class loss: 1.14380 | Running loss: 1.53412\n",
      "flip_x\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 134 | Classification loss: 0.21160 | Regression loss: 0.17588 | Whole Class loss: 1.13972 | Running loss: 1.52719\n",
      "shift\n",
      "shift\n",
      "Epoch: 0 | Iteration: 135 | Classification loss: 0.21010 | Regression loss: 0.17458 | Whole Class loss: 1.13599 | Running loss: 1.52067\n",
      "flip_x\n",
      "Epoch: 0 | Iteration: 136 | Classification loss: 0.21275 | Regression loss: 0.17687 | Whole Class loss: 1.14317 | Running loss: 1.53280\n",
      "flip_x\n",
      "rotate\n",
      "Epoch: 0 | Iteration: 137 | Classification loss: 0.21540 | Regression loss: 0.17934 | Whole Class loss: 1.14761 | Running loss: 1.54235\n",
      "Epoch: 0 | Iteration: 138 | Classification loss: 0.21798 | Regression loss: 0.18196 | Whole Class loss: 1.15197 | Running loss: 1.55190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Iteration: 139 | Classification loss: 0.21647 | Regression loss: 0.18066 | Whole Class loss: 1.15040 | Running loss: 1.54753\n",
      "Evaluating dataset\n",
      "280/280\n",
      "mAP:\n",
      "0: 0.0\n",
      "1: 0.0\n",
      "2: 0.0\n",
      "flip_x\n",
      "flip_x\n",
      "flip_x\n",
      "scale\n",
      "Epoch: 1 | Iteration: 0 | Classification loss: 0.22062 | Regression loss: 0.18002 | Whole Class loss: 1.14135 | Running loss: 1.54198\n",
      "Epoch: 1 | Iteration: 1 | Classification loss: 0.21926 | Regression loss: 0.17883 | Whole Class loss: 1.13950 | Running loss: 1.53759\n",
      "shift\n",
      "shift\n",
      "Epoch: 1 | Iteration: 2 | Classification loss: 0.21792 | Regression loss: 0.17766 | Whole Class loss: 1.13742 | Running loss: 1.53301\n",
      "shift\n",
      "Epoch: 1 | Iteration: 3 | Classification loss: 0.22002 | Regression loss: 0.17962 | Whole Class loss: 1.13736 | Running loss: 1.53699\n",
      "Epoch: 1 | Iteration: 4 | Classification loss: 0.22190 | Regression loss: 0.18142 | Whole Class loss: 1.13742 | Running loss: 1.54075\n",
      "shift\n",
      "Epoch: 1 | Iteration: 5 | Classification loss: 0.22426 | Regression loss: 0.18359 | Whole Class loss: 1.14012 | Running loss: 1.54796\n",
      "shift\n",
      "scale\n",
      "Epoch: 1 | Iteration: 6 | Classification loss: 0.22629 | Regression loss: 0.18558 | Whole Class loss: 1.14165 | Running loss: 1.55352\n",
      "Epoch: 1 | Iteration: 7 | Classification loss: 0.22491 | Regression loss: 0.18441 | Whole Class loss: 1.13982 | Running loss: 1.54913\n",
      "shift\n",
      "Epoch: 1 | Iteration: 8 | Classification loss: 0.22357 | Regression loss: 0.18325 | Whole Class loss: 1.14062 | Running loss: 1.54744\n",
      "scale\n",
      "Epoch: 1 | Iteration: 9 | Classification loss: 0.22225 | Regression loss: 0.18210 | Whole Class loss: 1.13946 | Running loss: 1.54381\n",
      "shift\n",
      "shift\n",
      "flip_x\n",
      "Epoch: 1 | Iteration: 10 | Classification loss: 0.22092 | Regression loss: 0.18097 | Whole Class loss: 1.14183 | Running loss: 1.54372\n",
      "shift\n",
      "shift\n",
      "shift\n",
      "Epoch: 1 | Iteration: 11 | Classification loss: 0.22320 | Regression loss: 0.18301 | Whole Class loss: 1.14138 | Running loss: 1.54759\n",
      "rotate\n",
      "Epoch: 1 | Iteration: 12 | Classification loss: 0.22191 | Regression loss: 0.18189 | Whole Class loss: 1.14009 | Running loss: 1.54389\n",
      "Epoch: 1 | Iteration: 13 | Classification loss: 0.22065 | Regression loss: 0.18078 | Whole Class loss: 1.13890 | Running loss: 1.54033\n",
      "scale\n",
      "scale\n",
      "Epoch: 1 | Iteration: 14 | Classification loss: 0.21941 | Regression loss: 0.17968 | Whole Class loss: 1.14037 | Running loss: 1.53946\n",
      "flip_x\n",
      "Epoch: 1 | Iteration: 15 | Classification loss: 0.22163 | Regression loss: 0.18166 | Whole Class loss: 1.14127 | Running loss: 1.54456\n",
      "shift\n",
      "Epoch: 1 | Iteration: 16 | Classification loss: 0.22334 | Regression loss: 0.18376 | Whole Class loss: 1.14149 | Running loss: 1.54859\n",
      "flip_x\n",
      "flip_x\n",
      "Epoch: 1 | Iteration: 17 | Classification loss: 0.22524 | Regression loss: 0.18599 | Whole Class loss: 1.14225 | Running loss: 1.55349\n",
      "shift\n",
      "Epoch: 1 | Iteration: 18 | Classification loss: 0.22405 | Regression loss: 0.18489 | Whole Class loss: 1.14170 | Running loss: 1.55064\n",
      "flip_x\n",
      "flip_x\n",
      "Epoch: 1 | Iteration: 19 | Classification loss: 0.22548 | Regression loss: 0.18659 | Whole Class loss: 1.14153 | Running loss: 1.55360\n",
      "Epoch: 1 | Iteration: 20 | Classification loss: 0.22692 | Regression loss: 0.18833 | Whole Class loss: 1.14161 | Running loss: 1.55685\n",
      "rotate\n",
      "Epoch: 1 | Iteration: 21 | Classification loss: 0.22828 | Regression loss: 0.18984 | Whole Class loss: 1.14182 | Running loss: 1.55993\n",
      "Epoch: 1 | Iteration: 22 | Classification loss: 0.22729 | Regression loss: 0.18874 | Whole Class loss: 1.14095 | Running loss: 1.55698\n",
      "noise\n",
      "flip_x\n",
      "flip_x\n",
      "Epoch: 1 | Iteration: 23 | Classification loss: 0.22669 | Regression loss: 0.18765 | Whole Class loss: 1.14045 | Running loss: 1.55480\n",
      "scale\n",
      "Epoch: 1 | Iteration: 24 | Classification loss: 0.22761 | Regression loss: 0.18909 | Whole Class loss: 1.14022 | Running loss: 1.55693\n",
      "Epoch: 1 | Iteration: 25 | Classification loss: 0.22676 | Regression loss: 0.18801 | Whole Class loss: 1.13974 | Running loss: 1.55451\n",
      "flip_x\n",
      "flip_x\n",
      "shift\n",
      "flip_x\n",
      "Epoch: 1 | Iteration: 26 | Classification loss: 0.22568 | Regression loss: 0.18695 | Whole Class loss: 1.13896 | Running loss: 1.55159\n",
      "rotate\n",
      "Epoch: 1 | Iteration: 27 | Classification loss: 0.22454 | Regression loss: 0.18590 | Whole Class loss: 1.13817 | Running loss: 1.54861\n",
      "shift\n",
      "shift\n",
      "Epoch: 1 | Iteration: 28 | Classification loss: 0.22337 | Regression loss: 0.18486 | Whole Class loss: 1.13727 | Running loss: 1.54550\n",
      "shift\n",
      "rotate\n",
      "Epoch: 1 | Iteration: 29 | Classification loss: 0.22217 | Regression loss: 0.18384 | Whole Class loss: 1.13668 | Running loss: 1.54269\n",
      "Epoch: 1 | Iteration: 30 | Classification loss: 0.22097 | Regression loss: 0.18282 | Whole Class loss: 1.13545 | Running loss: 1.53924\n",
      "flip_x\n",
      "Epoch: 1 | Iteration: 31 | Classification loss: 0.21977 | Regression loss: 0.18182 | Whole Class loss: 1.13394 | Running loss: 1.53553\n",
      "scale\n",
      "Epoch: 1 | Iteration: 32 | Classification loss: 0.22304 | Regression loss: 0.18318 | Whole Class loss: 1.13513 | Running loss: 1.54134\n",
      "Epoch: 1 | Iteration: 33 | Classification loss: 0.22183 | Regression loss: 0.18218 | Whole Class loss: 1.13366 | Running loss: 1.53767\n",
      "rotate\n",
      "Epoch: 1 | Iteration: 34 | Classification loss: 0.22064 | Regression loss: 0.18120 | Whole Class loss: 1.13253 | Running loss: 1.53437\n",
      "flip_x\n",
      "flip_x\n",
      "Epoch: 1 | Iteration: 35 | Classification loss: 0.21947 | Regression loss: 0.18022 | Whole Class loss: 1.13084 | Running loss: 1.53054\n",
      "rotate\n",
      "Epoch: 1 | Iteration: 36 | Classification loss: 0.22163 | Regression loss: 0.18224 | Whole Class loss: 1.13241 | Running loss: 1.53628\n",
      "Epoch: 1 | Iteration: 37 | Classification loss: 0.22398 | Regression loss: 0.18428 | Whole Class loss: 1.13639 | Running loss: 1.54465\n",
      "flip_x\n",
      "scale\n",
      "Epoch: 1 | Iteration: 38 | Classification loss: 0.22282 | Regression loss: 0.18330 | Whole Class loss: 1.13641 | Running loss: 1.54253\n",
      "Epoch: 1 | Iteration: 39 | Classification loss: 0.22165 | Regression loss: 0.18234 | Whole Class loss: 1.13453 | Running loss: 1.53852\n",
      "rotate\n",
      "shift\n",
      "scale\n",
      "Epoch: 1 | Iteration: 40 | Classification loss: 0.22052 | Regression loss: 0.18138 | Whole Class loss: 1.13373 | Running loss: 1.53563\n",
      "Epoch: 1 | Iteration: 41 | Classification loss: 0.22240 | Regression loss: 0.18292 | Whole Class loss: 1.13608 | Running loss: 1.54141\n",
      "shift\n",
      "flip_x\n",
      "shift\n",
      "Epoch: 1 | Iteration: 42 | Classification loss: 0.22127 | Regression loss: 0.18197 | Whole Class loss: 1.13368 | Running loss: 1.53692\n",
      "Epoch: 1 | Iteration: 43 | Classification loss: 0.22316 | Regression loss: 0.18337 | Whole Class loss: 1.13625 | Running loss: 1.54278\n",
      "Epoch: 1 | Iteration: 44 | Classification loss: 0.22205 | Regression loss: 0.18243 | Whole Class loss: 1.13444 | Running loss: 1.53892\n",
      "shift\n",
      "Epoch: 1 | Iteration: 45 | Classification loss: 0.22438 | Regression loss: 0.18410 | Whole Class loss: 1.13688 | Running loss: 1.54536\n",
      "scale\n",
      "Epoch: 1 | Iteration: 46 | Classification loss: 0.22327 | Regression loss: 0.18317 | Whole Class loss: 1.13516 | Running loss: 1.54159\n",
      "Epoch: 1 | Iteration: 47 | Classification loss: 0.22217 | Regression loss: 0.18224 | Whole Class loss: 1.13306 | Running loss: 1.53747\n",
      "flip_x\n",
      "flip_x\n",
      "shift\n",
      "noise\n",
      "Epoch: 1 | Iteration: 48 | Classification loss: 0.22108 | Regression loss: 0.18132 | Whole Class loss: 1.13644 | Running loss: 1.53884\n",
      "Epoch: 1 | Iteration: 49 | Classification loss: 0.22287 | Regression loss: 0.18270 | Whole Class loss: 1.13785 | Running loss: 1.54342\n",
      "shift\n",
      "shift\n",
      "Epoch: 1 | Iteration: 50 | Classification loss: 0.22463 | Regression loss: 0.18404 | Whole Class loss: 1.13745 | Running loss: 1.54612\n",
      "flip_x\n",
      "rotate\n",
      "Epoch: 1 | Iteration: 51 | Classification loss: 0.22355 | Regression loss: 0.18313 | Whole Class loss: 1.13544 | Running loss: 1.54212\n",
      "Epoch: 1 | Iteration: 52 | Classification loss: 0.22248 | Regression loss: 0.18223 | Whole Class loss: 1.13352 | Running loss: 1.53823\n",
      "scale\n",
      "Epoch: 1 | Iteration: 53 | Classification loss: 0.22144 | Regression loss: 0.18133 | Whole Class loss: 1.13160 | Running loss: 1.53437\n",
      "flip_x\n",
      "flip_x\n",
      "Epoch: 1 | Iteration: 54 | Classification loss: 0.22039 | Regression loss: 0.18045 | Whole Class loss: 1.13003 | Running loss: 1.53087\n",
      "flip_x\n",
      "scale\n",
      "Epoch: 1 | Iteration: 55 | Classification loss: 0.21935 | Regression loss: 0.17957 | Whole Class loss: 1.12974 | Running loss: 1.52866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Iteration: 56 | Classification loss: 0.22103 | Regression loss: 0.18106 | Whole Class loss: 1.13026 | Running loss: 1.53234\n",
      "noise\n",
      "Epoch: 1 | Iteration: 57 | Classification loss: 0.22001 | Regression loss: 0.18019 | Whole Class loss: 1.12779 | Running loss: 1.52799\n",
      "Epoch: 1 | Iteration: 58 | Classification loss: 0.22169 | Regression loss: 0.18161 | Whole Class loss: 1.13055 | Running loss: 1.53385\n",
      "noise\n",
      "Epoch: 1 | Iteration: 59 | Classification loss: 0.22068 | Regression loss: 0.18074 | Whole Class loss: 1.13079 | Running loss: 1.53221\n",
      "scale\n",
      "Epoch: 1 | Iteration: 60 | Classification loss: 0.21967 | Regression loss: 0.17988 | Whole Class loss: 1.12901 | Running loss: 1.52856\n",
      "noise\n",
      "Epoch: 1 | Iteration: 61 | Classification loss: 0.21867 | Regression loss: 0.17904 | Whole Class loss: 1.12814 | Running loss: 1.52585\n",
      "shift\n",
      "shift\n",
      "scale\n",
      "Epoch: 1 | Iteration: 62 | Classification loss: 0.22035 | Regression loss: 0.18062 | Whole Class loss: 1.12783 | Running loss: 1.52880\n",
      "Epoch: 1 | Iteration: 63 | Classification loss: 0.21934 | Regression loss: 0.17978 | Whole Class loss: 1.12632 | Running loss: 1.52544\n",
      "flip_x\n",
      "flip_x\n",
      "shift\n",
      "Epoch: 1 | Iteration: 64 | Classification loss: 0.21834 | Regression loss: 0.17894 | Whole Class loss: 1.12453 | Running loss: 1.52182\n",
      "scale\n",
      "Epoch: 1 | Iteration: 65 | Classification loss: 0.21735 | Regression loss: 0.17811 | Whole Class loss: 1.12362 | Running loss: 1.51909\n",
      "Epoch: 1 | Iteration: 66 | Classification loss: 0.22179 | Regression loss: 0.18182 | Whole Class loss: 1.12891 | Running loss: 1.53252\n",
      "noise\n",
      "Epoch: 1 | Iteration: 67 | Classification loss: 0.22078 | Regression loss: 0.18099 | Whole Class loss: 1.12667 | Running loss: 1.52845\n",
      "flip_x\n",
      "Epoch: 1 | Iteration: 68 | Classification loss: 0.21981 | Regression loss: 0.18016 | Whole Class loss: 1.12567 | Running loss: 1.52564\n",
      "Epoch: 1 | Iteration: 69 | Classification loss: 0.22136 | Regression loss: 0.18153 | Whole Class loss: 1.12643 | Running loss: 1.52932\n",
      "shift\n",
      "scale\n",
      "Epoch: 1 | Iteration: 70 | Classification loss: 0.22037 | Regression loss: 0.18071 | Whole Class loss: 1.12505 | Running loss: 1.52613\n",
      "Epoch: 1 | Iteration: 71 | Classification loss: 0.21939 | Regression loss: 0.17989 | Whole Class loss: 1.12486 | Running loss: 1.52414\n",
      "flip_x\n",
      "shift\n",
      "scale\n",
      "Epoch: 1 | Iteration: 72 | Classification loss: 0.21843 | Regression loss: 0.17909 | Whole Class loss: 1.12410 | Running loss: 1.52161\n",
      "flip_x\n",
      "shift\n",
      "Epoch: 1 | Iteration: 73 | Classification loss: 0.21747 | Regression loss: 0.17829 | Whole Class loss: 1.12321 | Running loss: 1.51896\n",
      "shift\n",
      "Epoch: 1 | Iteration: 74 | Classification loss: 0.21651 | Regression loss: 0.17749 | Whole Class loss: 1.12108 | Running loss: 1.51509\n",
      "noise\n",
      "Epoch: 1 | Iteration: 75 | Classification loss: 0.21556 | Regression loss: 0.17671 | Whole Class loss: 1.11929 | Running loss: 1.51156\n",
      "Epoch: 1 | Iteration: 76 | Classification loss: 0.21734 | Regression loss: 0.17808 | Whole Class loss: 1.12213 | Running loss: 1.51755\n",
      "scale\n",
      "Epoch: 1 | Iteration: 77 | Classification loss: 0.21641 | Regression loss: 0.17730 | Whole Class loss: 1.12143 | Running loss: 1.51513\n",
      "noise\n",
      "noise\n",
      "Epoch: 1 | Iteration: 78 | Classification loss: 0.21549 | Regression loss: 0.17652 | Whole Class loss: 1.12018 | Running loss: 1.51219\n",
      "scale\n",
      "Epoch: 1 | Iteration: 79 | Classification loss: 0.21698 | Regression loss: 0.17799 | Whole Class loss: 1.11921 | Running loss: 1.51418\n",
      "Epoch: 1 | Iteration: 80 | Classification loss: 0.21604 | Regression loss: 0.17722 | Whole Class loss: 1.11661 | Running loss: 1.50987\n",
      "flip_x\n",
      "noise\n",
      "Epoch: 1 | Iteration: 81 | Classification loss: 0.21755 | Regression loss: 0.17882 | Whole Class loss: 1.11730 | Running loss: 1.51367\n",
      "rotate\n",
      "shift\n",
      "Epoch: 1 | Iteration: 82 | Classification loss: 0.21664 | Regression loss: 0.17805 | Whole Class loss: 1.11654 | Running loss: 1.51123\n",
      "shift\n",
      "flip_x\n",
      "Epoch: 1 | Iteration: 83 | Classification loss: 0.21866 | Regression loss: 0.17938 | Whole Class loss: 1.12627 | Running loss: 1.52431\n",
      "scale\n",
      "Epoch: 1 | Iteration: 84 | Classification loss: 0.22037 | Regression loss: 0.18091 | Whole Class loss: 1.12803 | Running loss: 1.52932\n",
      "Epoch: 1 | Iteration: 85 | Classification loss: 0.22186 | Regression loss: 0.18214 | Whole Class loss: 1.13227 | Running loss: 1.53627\n",
      "flip_x\n",
      "shift\n",
      "shift\n",
      "Epoch: 1 | Iteration: 86 | Classification loss: 0.22093 | Regression loss: 0.18137 | Whole Class loss: 1.12966 | Running loss: 1.53196\n",
      "shift\n",
      "Epoch: 1 | Iteration: 87 | Classification loss: 0.22238 | Regression loss: 0.18254 | Whole Class loss: 1.13143 | Running loss: 1.53635\n",
      "noise\n",
      "Epoch: 1 | Iteration: 88 | Classification loss: 0.22146 | Regression loss: 0.18178 | Whole Class loss: 1.12942 | Running loss: 1.53266\n",
      "Epoch: 1 | Iteration: 89 | Classification loss: 0.22055 | Regression loss: 0.18102 | Whole Class loss: 1.12656 | Running loss: 1.52813\n",
      "Epoch: 1 | Iteration: 90 | Classification loss: 0.21966 | Regression loss: 0.18027 | Whole Class loss: 1.12510 | Running loss: 1.52502\n",
      "noise\n",
      "Epoch: 1 | Iteration: 91 | Classification loss: 0.21876 | Regression loss: 0.17952 | Whole Class loss: 1.12272 | Running loss: 1.52101\n",
      "Epoch: 1 | Iteration: 92 | Classification loss: 0.21788 | Regression loss: 0.17878 | Whole Class loss: 1.12126 | Running loss: 1.51792\n",
      "scale\n",
      "Epoch: 1 | Iteration: 93 | Classification loss: 0.21925 | Regression loss: 0.18002 | Whole Class loss: 1.12212 | Running loss: 1.52139\n",
      "shift\n",
      "Epoch: 1 | Iteration: 94 | Classification loss: 0.21837 | Regression loss: 0.17929 | Whole Class loss: 1.12187 | Running loss: 1.51953\n",
      "Epoch: 1 | Iteration: 95 | Classification loss: 0.21986 | Regression loss: 0.18021 | Whole Class loss: 1.12826 | Running loss: 1.52832\n",
      "flip_x\n",
      "Epoch: 1 | Iteration: 96 | Classification loss: 0.21898 | Regression loss: 0.17948 | Whole Class loss: 1.12531 | Running loss: 1.52377\n",
      "noise\n",
      "Epoch: 1 | Iteration: 97 | Classification loss: 0.22034 | Regression loss: 0.18066 | Whole Class loss: 1.12698 | Running loss: 1.52797\n",
      "Epoch: 1 | Iteration: 98 | Classification loss: 0.21947 | Regression loss: 0.17993 | Whole Class loss: 1.12682 | Running loss: 1.52623\n",
      "scale\n",
      "Epoch: 1 | Iteration: 99 | Classification loss: 0.21862 | Regression loss: 0.17921 | Whole Class loss: 1.12553 | Running loss: 1.52337\n",
      "Epoch: 1 | Iteration: 100 | Classification loss: 0.21778 | Regression loss: 0.17850 | Whole Class loss: 1.12421 | Running loss: 1.52050\n",
      "flip_x\n",
      "Epoch: 1 | Iteration: 101 | Classification loss: 0.21694 | Regression loss: 0.17779 | Whole Class loss: 1.12265 | Running loss: 1.51738\n",
      "Epoch: 1 | Iteration: 102 | Classification loss: 0.21611 | Regression loss: 0.17709 | Whole Class loss: 1.12160 | Running loss: 1.51479\n",
      "shift\n",
      "Epoch: 1 | Iteration: 103 | Classification loss: 0.21527 | Regression loss: 0.17639 | Whole Class loss: 1.11861 | Running loss: 1.51028\n",
      "Epoch: 1 | Iteration: 104 | Classification loss: 0.21445 | Regression loss: 0.17570 | Whole Class loss: 1.11683 | Running loss: 1.50698\n",
      "shift\n",
      "scale\n",
      "Epoch: 1 | Iteration: 105 | Classification loss: 0.21363 | Regression loss: 0.17501 | Whole Class loss: 1.11498 | Running loss: 1.50362\n",
      "Epoch: 1 | Iteration: 106 | Classification loss: 0.21491 | Regression loss: 0.17603 | Whole Class loss: 1.11572 | Running loss: 1.50666\n",
      "shift\n",
      "shift\n",
      "Epoch: 1 | Iteration: 107 | Classification loss: 0.21409 | Regression loss: 0.17535 | Whole Class loss: 1.12208 | Running loss: 1.51153\n",
      "rotate\n",
      "Epoch: 1 | Iteration: 108 | Classification loss: 0.21328 | Regression loss: 0.17468 | Whole Class loss: 1.12146 | Running loss: 1.50942\n",
      "Epoch: 1 | Iteration: 109 | Classification loss: 0.21248 | Regression loss: 0.17400 | Whole Class loss: 1.11940 | Running loss: 1.50589\n",
      "flip_x\n",
      "shift\n",
      "Epoch: 1 | Iteration: 110 | Classification loss: 0.21389 | Regression loss: 0.17525 | Whole Class loss: 1.12413 | Running loss: 1.51327\n",
      "Epoch: 1 | Iteration: 111 | Classification loss: 0.21515 | Regression loss: 0.17624 | Whole Class loss: 1.12508 | Running loss: 1.51646\n",
      "shift\n",
      "shift\n",
      "Epoch: 1 | Iteration: 112 | Classification loss: 0.21434 | Regression loss: 0.17557 | Whole Class loss: 1.12603 | Running loss: 1.51594\n",
      "scale\n",
      "Epoch: 1 | Iteration: 113 | Classification loss: 0.21558 | Regression loss: 0.17662 | Whole Class loss: 1.12971 | Running loss: 1.52191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Iteration: 114 | Classification loss: 0.21478 | Regression loss: 0.17595 | Whole Class loss: 1.12947 | Running loss: 1.52020\n",
      "noise\n",
      "Epoch: 1 | Iteration: 115 | Classification loss: 0.21398 | Regression loss: 0.17529 | Whole Class loss: 1.13131 | Running loss: 1.52058\n",
      "shift\n",
      "scale\n",
      "Epoch: 1 | Iteration: 116 | Classification loss: 0.21321 | Regression loss: 0.17464 | Whole Class loss: 1.12979 | Running loss: 1.51764\n",
      "shift\n",
      "shift\n",
      "Epoch: 1 | Iteration: 117 | Classification loss: 0.21451 | Regression loss: 0.17576 | Whole Class loss: 1.13094 | Running loss: 1.52120\n",
      "flip_x\n",
      "shift\n",
      "Epoch: 1 | Iteration: 118 | Classification loss: 0.21374 | Regression loss: 0.17510 | Whole Class loss: 1.13038 | Running loss: 1.51921\n",
      "noise\n",
      "Epoch: 1 | Iteration: 119 | Classification loss: 0.21297 | Regression loss: 0.17445 | Whole Class loss: 1.12918 | Running loss: 1.51660\n",
      "Epoch: 1 | Iteration: 120 | Classification loss: 0.21220 | Regression loss: 0.17381 | Whole Class loss: 1.12741 | Running loss: 1.51343\n",
      "flip_x\n",
      "flip_x\n",
      "flip_x\n",
      "shift\n",
      "Epoch: 1 | Iteration: 121 | Classification loss: 0.21145 | Regression loss: 0.17317 | Whole Class loss: 1.12630 | Running loss: 1.51092\n",
      "flip_x\n",
      "flip_x\n",
      "Epoch: 1 | Iteration: 122 | Classification loss: 0.21277 | Regression loss: 0.17440 | Whole Class loss: 1.12704 | Running loss: 1.51422\n",
      "scale\n",
      "Epoch: 1 | Iteration: 123 | Classification loss: 0.21202 | Regression loss: 0.17377 | Whole Class loss: 1.12581 | Running loss: 1.51160\n",
      "Epoch: 1 | Iteration: 124 | Classification loss: 0.21127 | Regression loss: 0.17314 | Whole Class loss: 1.12461 | Running loss: 1.50901\n",
      "shift\n",
      "Epoch: 1 | Iteration: 125 | Classification loss: 0.21052 | Regression loss: 0.17251 | Whole Class loss: 1.12367 | Running loss: 1.50671\n",
      "flip_x\n",
      "shift\n",
      "Epoch: 1 | Iteration: 126 | Classification loss: 0.20978 | Regression loss: 0.17189 | Whole Class loss: 1.12289 | Running loss: 1.50456\n",
      "shift\n",
      "Epoch: 1 | Iteration: 127 | Classification loss: 0.20905 | Regression loss: 0.17127 | Whole Class loss: 1.12186 | Running loss: 1.50217\n",
      "Epoch: 1 | Iteration: 128 | Classification loss: 0.20832 | Regression loss: 0.17065 | Whole Class loss: 1.12068 | Running loss: 1.49965\n",
      "flip_x\n",
      "shift\n",
      "flip_x\n",
      "Epoch: 1 | Iteration: 129 | Classification loss: 0.20758 | Regression loss: 0.17004 | Whole Class loss: 1.11883 | Running loss: 1.49646\n",
      "scale\n",
      "Epoch: 1 | Iteration: 130 | Classification loss: 0.20685 | Regression loss: 0.16944 | Whole Class loss: 1.11802 | Running loss: 1.49431\n",
      "Epoch: 1 | Iteration: 131 | Classification loss: 0.21188 | Regression loss: 0.17233 | Whole Class loss: 1.12559 | Running loss: 1.50980\n",
      "Epoch: 1 | Iteration: 132 | Classification loss: 0.21114 | Regression loss: 0.17172 | Whole Class loss: 1.12726 | Running loss: 1.51012\n",
      "shift\n",
      "Epoch: 1 | Iteration: 133 | Classification loss: 0.21040 | Regression loss: 0.17112 | Whole Class loss: 1.12530 | Running loss: 1.50681\n",
      "flip_x\n",
      "flip_x\n",
      "flip_x\n",
      "Epoch: 1 | Iteration: 134 | Classification loss: 0.20967 | Regression loss: 0.17052 | Whole Class loss: 1.12294 | Running loss: 1.50313\n",
      "shift\n",
      "shift\n",
      "Epoch: 1 | Iteration: 135 | Classification loss: 0.20894 | Regression loss: 0.16992 | Whole Class loss: 1.12148 | Running loss: 1.50034\n",
      "flip_x\n",
      "Epoch: 1 | Iteration: 136 | Classification loss: 0.20822 | Regression loss: 0.16933 | Whole Class loss: 1.12031 | Running loss: 1.49786\n",
      "flip_x\n",
      "rotate\n",
      "Epoch: 1 | Iteration: 137 | Classification loss: 0.20967 | Regression loss: 0.17069 | Whole Class loss: 1.12435 | Running loss: 1.50471\n",
      "Epoch: 1 | Iteration: 138 | Classification loss: 0.20895 | Regression loss: 0.17010 | Whole Class loss: 1.12370 | Running loss: 1.50275\n",
      "shift\n",
      "shift\n",
      "rotate\n",
      "Epoch: 1 | Iteration: 139 | Classification loss: 0.20824 | Regression loss: 0.16951 | Whole Class loss: 1.12213 | Running loss: 1.49988\n",
      "Epoch: 1 | Iteration: 140 | Classification loss: 0.21018 | Regression loss: 0.17084 | Whole Class loss: 1.12606 | Running loss: 1.50708\n",
      "flip_x\n",
      "Epoch: 1 | Iteration: 141 | Classification loss: 0.20946 | Regression loss: 0.17026 | Whole Class loss: 1.12475 | Running loss: 1.50447\n",
      "Epoch: 1 | Iteration: 142 | Classification loss: 0.21092 | Regression loss: 0.17118 | Whole Class loss: 1.13103 | Running loss: 1.51313\n",
      "scale\n",
      "Epoch: 1 | Iteration: 143 | Classification loss: 0.21021 | Regression loss: 0.17060 | Whole Class loss: 1.12948 | Running loss: 1.51029\n",
      "Epoch: 1 | Iteration: 144 | Classification loss: 0.20950 | Regression loss: 0.17002 | Whole Class loss: 1.12804 | Running loss: 1.50757\n",
      "flip_x\n",
      "flip_x\n",
      "Epoch: 1 | Iteration: 145 | Classification loss: 0.20880 | Regression loss: 0.16945 | Whole Class loss: 1.12641 | Running loss: 1.50466\n",
      "flip_x\n",
      "Epoch: 1 | Iteration: 146 | Classification loss: 0.20811 | Regression loss: 0.16888 | Whole Class loss: 1.12500 | Running loss: 1.50199\n",
      "noise\n",
      "Epoch: 1 | Iteration: 147 | Classification loss: 0.20925 | Regression loss: 0.16981 | Whole Class loss: 1.12780 | Running loss: 1.50686\n",
      "Epoch: 1 | Iteration: 148 | Classification loss: 0.20856 | Regression loss: 0.16924 | Whole Class loss: 1.12656 | Running loss: 1.50436\n",
      "flip_x\n",
      "Epoch: 1 | Iteration: 149 | Classification loss: 0.20971 | Regression loss: 0.17032 | Whole Class loss: 1.12681 | Running loss: 1.50684\n",
      "Evaluating dataset\n",
      "300/300\n",
      "mAP:\n",
      "0: 0.0\n",
      "1: 0.0\n",
      "2: 0.0\n",
      "flip_x\n",
      "flip_x\n",
      "flip_x\n",
      "scale\n",
      "Epoch: 1 | Iteration: 0 | Classification loss: 0.21497 | Regression loss: 0.17938 | Whole Class loss: 1.14832 | Running loss: 1.54267\n",
      "Epoch: 1 | Iteration: 1 | Classification loss: 0.21350 | Regression loss: 0.17811 | Whole Class loss: 1.14408 | Running loss: 1.53569\n",
      "shift\n"
     ]
    }
   ],
   "source": [
    "VAL_SIZE = 15\n",
    "count = [2000,2000]\n",
    "import traceback\n",
    "for epoch_num in range(EPOCHS):\n",
    "\n",
    "    for i in range(2):\n",
    "        retinanets[i].train()\n",
    "        retinanets[i].module.freeze_bn()\n",
    "        epoch_loss = []\n",
    "        \n",
    "        for iter_num, data in enumerate(dataloader_train[i]):\n",
    "            if 1 == 1:\n",
    "            #try:\n",
    "                optimizer[i].zero_grad()\n",
    "\n",
    "                focal_loss, whole_class_loss = retinanets[i]([Variable(data['img'].cuda().float()), Variable(data['annot'].cuda())])\n",
    "                classification_loss, regression_loss = focal_loss\n",
    "                classification_loss = classification_loss.mean()\n",
    "                regression_loss = regression_loss.mean()\n",
    "                whole_class_loss = whole_class_loss.mean()\n",
    "                loss = classification_loss + regression_loss + whole_class_loss\n",
    "\n",
    "                if bool(loss == 0):\n",
    "                    continue\n",
    "                #反向传播？\n",
    "                loss.backward()\n",
    "\n",
    "                #这是干嘛？？TODO\n",
    "                torch.nn.utils.clip_grad_norm_(retinanets[i].parameters(), 0.1)\n",
    "\n",
    "                #这?TODO\n",
    "                optimizer[i].step()\n",
    "\n",
    "                loss_hist[i].append(float(loss))\n",
    "                classloss_hist[i].append(float(classification_loss))\n",
    "                regressloss_hist[i].append(float(regression_loss))\n",
    "                wholeclassloss_hist[i].append(float(whole_class_loss))\n",
    "                epoch_loss.append(float(loss))\n",
    "                \n",
    "                print('Epoch: {} | Iteration: {} | Classification loss: {:1.5f} | Regression loss: {:1.5f} | Whole Class loss: {:1.5f} | Running loss: {:1.5f}'.format(epoch_num, iter_num, np.mean(classloss_hist[i]), np.mean(regressloss_hist[i]), np.mean(wholeclassloss_hist[i]), np.mean(loss_hist[i])))\n",
    "                vis.line(X=torch.Tensor([count[i]]), Y=torch.Tensor([np.mean(loss_hist[i])]), win='train loss '+str(i), update='append' ,opts={'title':'train loss '+str(i)})\n",
    "                vis.line(X=torch.Tensor([count[i]]), Y=torch.Tensor([np.mean(classloss_hist[i])]), win='classification loss '+str(i), update='append' ,opts={'title':'classification loss '+str(i)})\n",
    "                vis.line(X=torch.Tensor([count[i]]), Y=torch.Tensor([np.mean(regressloss_hist[i])]), win='regression loss '+str(i), update='append' ,opts={'title':'regression loss '+str(i)})\n",
    "                vis.line(X=torch.Tensor([count[i]]), Y=torch.Tensor([np.mean(wholeclassloss_hist[i])]), win='whole class loss '+str(i), update='append' ,opts={'title':'whole class loss '+str(i)})\n",
    "\n",
    "                count[i] += 1\n",
    "                vis.save(['retinanet_seresnextTest'])\n",
    "\n",
    "                del classification_loss\n",
    "                del regression_loss\n",
    "#                 print(count[i])\n",
    "#                 if count[i] % VAL_SIZE == 0:\n",
    "#                     print(\"Evaluating dataset\")\n",
    "#                     retinanets[i].eval()\n",
    "#                     mAP = csv_eval.evaluate(dataset_val[i],retinanets[i])\n",
    "#                     vis.line(X=torch.Tensor([count[i]]), Y=torch.Tensor([mAP[0][0]]), win='val mAP '+str(i), update='append' ,opts={'title':'mAP val '+str(i)})\n",
    "#                     vis.save(['retinanet_seresnextTest'])\n",
    "#                     #torch.save(retinanets[i].module, 'weights_stage1/{}_seresnext101_{}.pt'.format(i, epoch_num))\n",
    "#                     retinanets[i].train()\n",
    "#             except Exception as e:\n",
    "#                 print(e)\n",
    "#                 continue\n",
    "\n",
    "\n",
    "        print(\"Evaluating dataset\")\n",
    "        retinanets[i].eval()\n",
    "    #     for index,data in enumerate(dataloader_val):\n",
    "    #         #data = dataset[index]\n",
    "    #         scale = data['scale']\n",
    "    #         # run network\n",
    "    #         #scores, labels, boxes = retinanet(data['img'].permute(2, 0, 1).cuda().float().unsqueeze(dim=0))\n",
    "    #         print(Variable(data['img'].cuda()))\n",
    "    #         scores, labels, boxes = retinanet(Variable(data['img'].cuda()))\n",
    "    #         #mAP = csv_eval.evaluate(dataset_val,retinanet)\n",
    "#         try:\n",
    "        if 1 == 1:\n",
    "            mAP = csv_eval.evaluate(dataset_val[i],retinanets[i])\n",
    "            vis.line(X=torch.Tensor([epoch_num]), Y=torch.Tensor([mAP[1][0]]), win='val mAP '+str(i), update='append' ,opts={'title':'mAP val '+str(i)})\n",
    "            vis.save(['retinanet_seresnextTest'])\n",
    "#         except Exception as e:\n",
    "#             print(e)\n",
    "#             print( 'traceback.print_exc():', traceback.print_exc())\n",
    "#             continue\n",
    "        #这一步也看不懂？？TODO \n",
    "        scheduler[i].step(np.mean(epoch_loss))\n",
    "\n",
    "        #torch.save(retinanets[i].module, 'weights_stage1/{}_seresnext101_{}.pt'.format(i, epoch_num))\n",
    "    #     torch.save(retinanet.module, '{}_retinanet_{}.pt'.format(parser.dataset, epoch_num))\n",
    "\n",
    "for i in range(2):\n",
    "    retinanets[i].eval()\n",
    "    #torch.save(retinanets[i], 'weights_stage1/{}_model_final_seresnext101.pt'.format(i))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
