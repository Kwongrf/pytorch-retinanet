{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start importing package...\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "# %load retinanet_train.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "print(\"Start importing package...\")\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import argparse\n",
    "import pdb\n",
    "import collections\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, models, transforms\n",
    "import torchvision\n",
    "\n",
    "import model\n",
    "import mymodel\n",
    "from anchors import Anchors\n",
    "import losses\n",
    "from dataloader import CocoDataset, CSVDataset, collater, Resizer, AspectRatioBasedSampler, Augmenter, UnNormalizer, Normalizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from mydataloader import MyDataset\n",
    "import coco_eval\n",
    "import csv_eval\n",
    "import visdom\n",
    "vis = visdom.Visdom(env='retinanet_seresnext101')\n",
    "\n",
    "assert torch.__version__.split('.')[1] == '4'\n",
    "\n",
    "print('CUDA available: {}'.format(torch.cuda.is_available()))\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "#参数\n",
    "NAME=\"RSNA\"\n",
    "DATA_PATH = \"/data/krf/dataset\"\n",
    "CSV_TRAINS = [DATA_PATH + \"/csv_train0.csv\",DATA_PATH + \"/csv_train1.csv\",DATA_PATH + \"/csv_train2.csv\",DATA_PATH + \"/csv_train3.csv\"]\n",
    "CSV_VALS = [DATA_PATH + \"/csv_val0.csv\",DATA_PATH + \"/csv_val1.csv\",DATA_PATH + \"/csv_val2.csv\",DATA_PATH + \"/csv_val3.csv\"]\n",
    "CSV_CLASSES = DATA_PATH + \"/classes.csv\"\n",
    "DEPTH = 101\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE=2\n",
    "VAL_SIZE = 3000\n",
    "#TRAIN_SIZE = 100\n",
    "#数据预处理\n",
    "import csv\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25684/25684 [01:19<00:00, 324.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0] [2235, 2293, 2226, 2210]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# with open(DATA_PATH+\"/stage_1_train_labels.csv\") as f:\n",
    "#     reader = csv.reader(f)\n",
    "#     rows=[row for row in  reader]\n",
    "#     rows = rows[1:]\n",
    "#     random.shuffle(rows)\n",
    "#     for row in rows:\n",
    "#         row[0] = DATA_PATH+\"/stage_1_train_images/\"+row[0]+\".dcm\"\n",
    "#         if row[1] == '' and row[2] == '' and row[3] == '' and row[4] == '':\n",
    "#             row[5] = ''\n",
    "#         else:\n",
    "#             row[3] = str(float(row[1]) + float(row[3]))# x2 = x1 + w \n",
    "#             row[4] = str(float(row[2]) + float(row[4]))# y2 = y1 + h\n",
    "#     val_rows = rows[:VAL_SIZE]\n",
    "#     train_rows = rows[VAL_SIZE:]\n",
    "#     print(len(val_rows),len(train_rows))\n",
    "#     with open(CSV_TRAIN,'w') as f2:\n",
    "#         write = csv.writer(f2)\n",
    "#         write.writerows(train_rows)\n",
    "#         print(\"csv_train 写入完毕\")\n",
    "#     with open(CSV_VAL,'w') as f3:\n",
    "#         write = csv.writer(f3)\n",
    "#         write.writerows(val_rows)\n",
    "#         print(\"csv_val 写入完毕\")\n",
    "\n",
    "# with open(CSV_CLASSES,'w') as f:\n",
    "#     write = csv.writer(f)\n",
    "#     row = ['1','0']\n",
    "#     write.writerow(row)\n",
    "#     print(\"csv_classes 写入完毕\")\n",
    "\n",
    "\n",
    "\n",
    "# #每次跑这个函数之前需要先删除之前的\n",
    "\n",
    "# df = pd.read_csv(DATA_PATH+\"/stage_1_train_labels.csv\")\n",
    "# train_images = os.listdir(DATA_PATH+\"/stage_1_train_images\")\n",
    "# random.shuffle(train_images)#打乱图片顺序\n",
    "# count = 0\n",
    "# pos_cnt_train = [0,0,0,0]\n",
    "# pos_cnt_val = [0,0,0,0]\n",
    "# for img_name in tqdm(train_images):\n",
    "#     results = df[df['patientId']==img_name.split('.')[0]].values\n",
    "#     for row in results:\n",
    "#         row[0] = DATA_PATH+\"/stage_1_train_images/\"+row[0]+\".dcm\"\n",
    "#         if row[5] == 1:\n",
    "#             pos_cnt_val[count % 4] += 1\n",
    "#         if row[1] >= 0 and row[1] <= 1024:\n",
    "#             row[3] = str(float(row[1]) + float(row[3]))# x2 = x1 + w \n",
    "#             row[4] = str(float(row[2]) + float(row[4]))# y2 = y1 + h\n",
    "#         else:\n",
    "#             row[1] = ''\n",
    "#             row[2] = ''\n",
    "#             row[3] = ''\n",
    "#             row[4] = ''\n",
    "#             row[5] = ''\n",
    "#         with open(CSV_VALS[count % 4],'a') as f:\n",
    "#             write = csv.writer(f)\n",
    "#             write.writerow(row)\n",
    "#         for i in range(4):\n",
    "#             if count % 4 == i:\n",
    "#                 continue\n",
    "#             else:\n",
    "#                 with open(CSV_TRAINS[count % 4],'a') as f:\n",
    "#                     write = csv.writer(f)\n",
    "#                     write.writerow(row) \n",
    "#     count += 1\n",
    "# print(pos_cnt_train,pos_cnt_val)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Loading data...\")\n",
    "\n",
    "#%time\n",
    "#制作数据loader\n",
    "dataset_train = []\n",
    "dataset_val = []\n",
    "\n",
    "for i in range(4): \n",
    "    dataset_train.append(MyDataset(train_file=CSV_TRAINS[i], class_list=CSV_CLASSES, transform=transforms.Compose([Normalizer(), Augmenter(), Resizer()])))\n",
    "    dataset_val.append(MyDataset(train_file=CSV_VALS[i], class_list=CSV_CLASSES, transform=transforms.Compose([Normalizer(), Resizer()])))\n",
    "\n",
    "#每次的sampler的参数：来源、batchsize、是否抛弃最后一层？？？\n",
    "\n",
    "# num_workers 同时工作的组？collater:校验用的吧\n",
    "dataloader_train = []\n",
    "dataloader_val = []\n",
    "\n",
    "for i in range(4):\n",
    "    sampler = AspectRatioBasedSampler(dataset_train[i], batch_size=BATCH_SIZE, drop_last=False)\n",
    "    sampler_val = AspectRatioBasedSampler(dataset_val[i], batch_size=1, drop_last=False)\n",
    "    dataloader_train.append(DataLoader(dataset_train[i], num_workers=1, collate_fn=collater, batch_sampler=sampler))\n",
    "    dataloader_val.append(DataLoader(dataset_val[i], num_workers=1, collate_fn=collater, batch_sampler=sampler_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num training images: 6421\n",
      "Num training images: 6421\n",
      "Num training images: 6421\n",
      "Num training images: 6421\n"
     ]
    }
   ],
   "source": [
    "retinanets = []\n",
    "# Create the model\n",
    "# if DEPTH == 18:\n",
    "#     retinanet = model.resnet18(num_classes=dataset_train.num_classes(), pretrained=True)\n",
    "# elif DEPTH == 34:\n",
    "#     retinanet = model.resnet34(num_classes=dataset_train.num_classes(), pretrained=True)\n",
    "# elif DEPTH == 50:\n",
    "#     for i in range(4):\n",
    "#         retinanets.append(model.resnet50(num_classes=dataset_train[i].num_classes(), pretrained=True))\n",
    "# elif DEPTH == 101:\n",
    "#     for i in range(4):\n",
    "#         retinanets.append(model.resnet101(num_classes=dataset_train[i].num_classes(), pretrained=True)) \n",
    "# elif DEPTH == 152:\n",
    "#     for i in range(4):\n",
    "#         retinanets.append(model.resnet152(num_classes=dataset_train[i].num_classes(), pretrained=True))\n",
    "# else:\n",
    "#     raise ValueError('Unsupported model depth, must be one of 18, 34, 50, 101, 152')\n",
    "#retinanet = torch.load('weights/RSNA_retinanet_5.pt')\n",
    "for i in range(4):\n",
    "    retinanets.append(mymodel.se_resnext101_32x4d(num_classes=dataset_train[i].num_classes()))\n",
    "optimizer = []\n",
    "scheduler = []\n",
    "loss_hist = []\n",
    "for i in range(4):\n",
    "    retinanets[i] = retinanets[i].cuda()\n",
    "    #变成并行\n",
    "    retinanets[i] = torch.nn.DataParallel(retinanets[i]).cuda()\n",
    "    #训练模式\n",
    "    retinanets[i].training = True\n",
    "    #学习率0.00001  \n",
    "    optimizer.append(optim.Adam(retinanets[i].parameters(), lr=1e-5))\n",
    "    #如果3个epoch损失没有减少则降低学习率\n",
    "    scheduler.append(optim.lr_scheduler.ReduceLROnPlateau(optimizer[i], patience=2, verbose=True))\n",
    "    # TODO 这是干什么 deque是为了高效实现插入和删除操作的双向列表，适合用于队列和栈：这里是定义了一个500的队列\n",
    "    loss_hist.append(collections.deque(maxlen=1000))\n",
    "    print('Num training images: {}'.format(len(dataset_train[i])))\n",
    "# In[5]:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/krf/anaconda/anaconda3/lib/python3.5/site-packages/torch/nn/modules/upsampling.py:122: UserWarning: nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Iteration: 2 | Classification loss: 0.56469 | Regression loss: 0.48521 | Running loss: 1.04990\n",
      "Epoch: 0 | Iteration: 3 | Classification loss: 0.56461 | Regression loss: 0.53214 | Running loss: 1.07332\n",
      "Epoch: 0 | Iteration: 4 | Classification loss: 0.56427 | Regression loss: 0.49650 | Running loss: 1.06914\n",
      "Epoch: 0 | Iteration: 7 | Classification loss: 1.12773 | Regression loss: 1.06248 | Running loss: 1.34941\n",
      "Epoch: 0 | Iteration: 8 | Classification loss: 0.56380 | Regression loss: 0.58180 | Running loss: 1.30865\n",
      "Epoch: 0 | Iteration: 11 | Classification loss: 1.12723 | Regression loss: 1.09925 | Running loss: 1.46162\n",
      "Epoch: 0 | Iteration: 12 | Classification loss: 1.12525 | Regression loss: 1.07197 | Running loss: 1.56670\n",
      "Epoch: 0 | Iteration: 13 | Classification loss: 0.56309 | Regression loss: 0.55151 | Running loss: 1.51019\n",
      "Epoch: 0 | Iteration: 14 | Classification loss: 0.56123 | Regression loss: 0.52122 | Running loss: 1.46266\n",
      "Epoch: 0 | Iteration: 15 | Classification loss: 0.56194 | Regression loss: 0.56896 | Running loss: 1.42949\n",
      "Epoch: 0 | Iteration: 19 | Classification loss: 0.55968 | Regression loss: 0.52976 | Running loss: 1.39857\n",
      "Epoch: 0 | Iteration: 21 | Classification loss: 1.11433 | Regression loss: 1.03520 | Running loss: 1.46115\n",
      "Epoch: 0 | Iteration: 23 | Classification loss: 0.55738 | Regression loss: 0.50525 | Running loss: 1.43050\n",
      "Epoch: 0 | Iteration: 29 | Classification loss: 0.55886 | Regression loss: 0.49728 | Running loss: 1.40376\n",
      "Epoch: 0 | Iteration: 31 | Classification loss: 0.54048 | Regression loss: 0.53269 | Running loss: 1.38172\n",
      "Epoch: 0 | Iteration: 34 | Classification loss: 0.55671 | Regression loss: 0.52005 | Running loss: 1.36266\n",
      "Epoch: 0 | Iteration: 39 | Classification loss: 0.54924 | Regression loss: 0.56676 | Running loss: 1.34815\n",
      "Epoch: 0 | Iteration: 47 | Classification loss: 0.54946 | Regression loss: 0.51185 | Running loss: 1.33221\n",
      "Epoch: 0 | Iteration: 49 | Classification loss: 0.54863 | Regression loss: 0.52481 | Running loss: 1.31859\n",
      "Epoch: 0 | Iteration: 56 | Classification loss: 0.53903 | Regression loss: 0.49804 | Running loss: 1.30452\n",
      "Epoch: 0 | Iteration: 59 | Classification loss: 0.52503 | Regression loss: 0.61065 | Running loss: 1.29648\n",
      "Epoch: 0 | Iteration: 60 | Classification loss: 0.55074 | Regression loss: 0.50979 | Running loss: 1.28575\n",
      "Epoch: 0 | Iteration: 63 | Classification loss: 0.52744 | Regression loss: 0.43292 | Running loss: 1.27160\n",
      "Epoch: 0 | Iteration: 64 | Classification loss: 0.53143 | Regression loss: 0.49778 | Running loss: 1.26151\n",
      "Epoch: 0 | Iteration: 66 | Classification loss: 0.53145 | Regression loss: 0.56117 | Running loss: 1.25475\n",
      "Epoch: 0 | Iteration: 72 | Classification loss: 0.53249 | Regression loss: 0.49885 | Running loss: 1.24616\n",
      "Epoch: 0 | Iteration: 73 | Classification loss: 0.52022 | Regression loss: 0.49924 | Running loss: 1.23776\n",
      "Epoch: 0 | Iteration: 76 | Classification loss: 0.51134 | Regression loss: 0.55835 | Running loss: 1.23176\n",
      "Epoch: 0 | Iteration: 78 | Classification loss: 0.52189 | Regression loss: 0.50521 | Running loss: 1.22470\n",
      "Epoch: 0 | Iteration: 79 | Classification loss: 0.50226 | Regression loss: 0.54954 | Running loss: 1.21894\n",
      "Epoch: 0 | Iteration: 80 | Classification loss: 0.46746 | Regression loss: 0.52162 | Running loss: 1.21152\n",
      "Epoch: 0 | Iteration: 81 | Classification loss: 0.48074 | Regression loss: 0.50826 | Running loss: 1.20457\n",
      "Epoch: 0 | Iteration: 82 | Classification loss: 0.32376 | Regression loss: 0.53620 | Running loss: 1.19413\n",
      "Epoch: 0 | Iteration: 90 | Classification loss: 0.41642 | Regression loss: 0.48175 | Running loss: 1.18542\n",
      "Epoch: 0 | Iteration: 96 | Classification loss: 0.47749 | Regression loss: 0.49459 | Running loss: 1.17933\n",
      "Epoch: 0 | Iteration: 98 | Classification loss: 0.45652 | Regression loss: 0.54537 | Running loss: 1.17440\n",
      "Epoch: 0 | Iteration: 99 | Classification loss: 1.33310 | Regression loss: 1.04847 | Running loss: 1.20702\n",
      "Epoch: 0 | Iteration: 103 | Classification loss: 0.51002 | Regression loss: 0.50788 | Running loss: 1.20205\n",
      "Epoch: 0 | Iteration: 106 | Classification loss: 0.49362 | Regression loss: 0.55878 | Running loss: 1.19821\n",
      "Epoch: 0 | Iteration: 107 | Classification loss: 0.52254 | Regression loss: 0.52311 | Running loss: 1.19440\n",
      "Epoch: 0 | Iteration: 110 | Classification loss: 1.16228 | Regression loss: 0.61598 | Running loss: 1.20864\n",
      "Epoch: 0 | Iteration: 112 | Classification loss: 0.38628 | Regression loss: 0.72975 | Running loss: 1.20643\n",
      "Epoch: 0 | Iteration: 114 | Classification loss: 0.51865 | Regression loss: 0.50147 | Running loss: 1.20210\n",
      "Epoch: 0 | Iteration: 117 | Classification loss: 0.43810 | Regression loss: 0.49671 | Running loss: 1.19602\n",
      "Epoch: 0 | Iteration: 118 | Classification loss: 0.42290 | Regression loss: 0.51107 | Running loss: 1.19020\n",
      "Epoch: 0 | Iteration: 119 | Classification loss: 0.77503 | Regression loss: 1.08228 | Running loss: 1.20470\n",
      "Epoch: 0 | Iteration: 122 | Classification loss: 0.42561 | Regression loss: 0.49241 | Running loss: 1.19860\n",
      "Epoch: 0 | Iteration: 124 | Classification loss: 0.38400 | Regression loss: 0.51934 | Running loss: 1.19245\n",
      "Epoch: 0 | Iteration: 129 | Classification loss: 0.41480 | Regression loss: 0.53168 | Running loss: 1.18743\n",
      "Epoch: 0 | Iteration: 132 | Classification loss: 0.68511 | Regression loss: 0.97394 | Running loss: 1.19687\n",
      "Epoch: 0 | Iteration: 133 | Classification loss: 0.31947 | Regression loss: 0.51931 | Running loss: 1.18984\n",
      "Epoch: 0 | Iteration: 138 | Classification loss: 0.32648 | Regression loss: 0.54063 | Running loss: 1.18364\n",
      "Epoch: 0 | Iteration: 142 | Classification loss: 0.41030 | Regression loss: 0.49153 | Running loss: 1.17832\n",
      "Epoch: 0 | Iteration: 145 | Classification loss: 0.24333 | Regression loss: 0.44061 | Running loss: 1.16917\n",
      "Epoch: 0 | Iteration: 148 | Classification loss: 0.41340 | Regression loss: 0.48443 | Running loss: 1.16423\n",
      "Epoch: 0 | Iteration: 150 | Classification loss: 0.68126 | Regression loss: 0.95285 | Running loss: 1.17262\n",
      "Epoch: 0 | Iteration: 151 | Classification loss: 0.32516 | Regression loss: 0.48180 | Running loss: 1.16621\n",
      "Epoch: 0 | Iteration: 155 | Classification loss: 0.43190 | Regression loss: 0.51626 | Running loss: 1.16245\n",
      "Epoch: 0 | Iteration: 161 | Classification loss: 0.36869 | Regression loss: 0.48419 | Running loss: 1.15720\n",
      "Epoch: 0 | Iteration: 162 | Classification loss: 0.74731 | Regression loss: 0.51422 | Running loss: 1.15894\n",
      "Epoch: 0 | Iteration: 163 | Classification loss: 0.52551 | Regression loss: 0.52332 | Running loss: 1.15713\n",
      "Epoch: 0 | Iteration: 164 | Classification loss: 0.40904 | Regression loss: 0.51104 | Running loss: 1.15331\n",
      "Epoch: 0 | Iteration: 166 | Classification loss: 0.44194 | Regression loss: 0.55878 | Running loss: 1.15089\n",
      "Epoch: 0 | Iteration: 169 | Classification loss: 0.29346 | Regression loss: 0.42830 | Running loss: 1.14418\n",
      "Epoch: 0 | Iteration: 171 | Classification loss: 0.40430 | Regression loss: 0.56257 | Running loss: 1.14146\n",
      "Epoch: 0 | Iteration: 174 | Classification loss: 0.29758 | Regression loss: 0.47858 | Running loss: 1.13592\n",
      "Epoch: 0 | Iteration: 175 | Classification loss: 0.30580 | Regression loss: 0.45788 | Running loss: 1.13037\n",
      "Epoch: 0 | Iteration: 176 | Classification loss: 0.35533 | Regression loss: 0.52105 | Running loss: 1.12663\n",
      "Epoch: 0 | Iteration: 177 | Classification loss: 0.38560 | Regression loss: 0.48167 | Running loss: 1.12287\n",
      "Epoch: 0 | Iteration: 180 | Classification loss: 0.33732 | Regression loss: 0.48115 | Running loss: 1.11852\n",
      "Epoch: 0 | Iteration: 181 | Classification loss: 0.75411 | Regression loss: 0.92842 | Running loss: 1.12647\n",
      "Epoch: 0 | Iteration: 185 | Classification loss: 0.47370 | Regression loss: 0.48539 | Running loss: 1.12414\n",
      "Epoch: 0 | Iteration: 188 | Classification loss: 0.46687 | Regression loss: 0.43687 | Running loss: 1.12112\n",
      "Epoch: 0 | Iteration: 193 | Classification loss: 0.67104 | Regression loss: 0.57567 | Running loss: 1.12282\n",
      "Epoch: 0 | Iteration: 194 | Classification loss: 0.42340 | Regression loss: 0.46477 | Running loss: 1.11969\n",
      "Epoch: 0 | Iteration: 198 | Classification loss: 0.28876 | Regression loss: 0.42541 | Running loss: 1.11436\n",
      "Epoch: 0 | Iteration: 201 | Classification loss: 0.71591 | Regression loss: 0.88820 | Running loss: 1.12072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Iteration: 202 | Classification loss: 0.72227 | Regression loss: 0.97027 | Running loss: 1.12805\n",
      "Epoch: 0 | Iteration: 203 | Classification loss: 0.41907 | Regression loss: 0.49326 | Running loss: 1.12532\n",
      "Epoch: 0 | Iteration: 204 | Classification loss: 0.35907 | Regression loss: 0.45819 | Running loss: 1.12147\n",
      "Epoch: 0 | Iteration: 205 | Classification loss: 0.36677 | Regression loss: 0.51812 | Running loss: 1.11855\n",
      "Epoch: 0 | Iteration: 206 | Classification loss: 0.27811 | Regression loss: 0.40129 | Running loss: 1.11319\n",
      "Epoch: 0 | Iteration: 207 | Classification loss: 0.29537 | Regression loss: 0.45148 | Running loss: 1.10878\n",
      "Epoch: 0 | Iteration: 208 | Classification loss: 0.35710 | Regression loss: 0.46477 | Running loss: 1.10536\n",
      "Epoch: 0 | Iteration: 209 | Classification loss: 0.31710 | Regression loss: 0.48694 | Running loss: 1.10182\n",
      "Epoch: 0 | Iteration: 216 | Classification loss: 0.34195 | Regression loss: 0.48927 | Running loss: 1.09867\n",
      "Epoch: 0 | Iteration: 222 | Classification loss: 0.27309 | Regression loss: 0.45271 | Running loss: 1.09438\n",
      "Epoch: 0 | Iteration: 224 | Classification loss: 0.33415 | Regression loss: 0.43533 | Running loss: 1.09069\n",
      "Epoch: 0 | Iteration: 232 | Classification loss: 0.79269 | Regression loss: 0.43322 | Running loss: 1.09221\n",
      "Epoch: 0 | Iteration: 241 | Classification loss: 0.46771 | Regression loss: 0.48611 | Running loss: 1.09067\n",
      "Epoch: 0 | Iteration: 244 | Classification loss: 0.58463 | Regression loss: 0.49880 | Running loss: 1.09059\n",
      "Epoch: 0 | Iteration: 247 | Classification loss: 0.36578 | Regression loss: 0.41459 | Running loss: 1.08722\n",
      "Epoch: 0 | Iteration: 249 | Classification loss: 0.62757 | Regression loss: 0.57850 | Running loss: 1.08850\n",
      "Epoch: 0 | Iteration: 252 | Classification loss: 0.33959 | Regression loss: 0.55963 | Running loss: 1.08649\n",
      "Epoch: 0 | Iteration: 256 | Classification loss: 0.26193 | Regression loss: 0.44258 | Running loss: 1.08246\n",
      "Epoch: 0 | Iteration: 259 | Classification loss: 0.50073 | Regression loss: 0.89814 | Running loss: 1.08576\n",
      "Epoch: 0 | Iteration: 260 | Classification loss: 0.35977 | Regression loss: 0.39728 | Running loss: 1.08237\n",
      "Epoch: 0 | Iteration: 261 | Classification loss: 0.27461 | Regression loss: 0.38155 | Running loss: 1.07802\n",
      "Epoch: 0 | Iteration: 262 | Classification loss: 0.81681 | Regression loss: 0.95074 | Running loss: 1.08499\n",
      "Epoch: 0 | Iteration: 263 | Classification loss: 0.48965 | Regression loss: 0.52453 | Running loss: 1.08428\n",
      "Epoch: 0 | Iteration: 271 | Classification loss: 0.35605 | Regression loss: 0.52671 | Running loss: 1.08228\n",
      "Epoch: 0 | Iteration: 274 | Classification loss: 0.25981 | Regression loss: 0.47964 | Running loss: 1.07892\n",
      "Epoch: 0 | Iteration: 277 | Classification loss: 0.34869 | Regression loss: 0.48013 | Running loss: 1.07649\n",
      "Epoch: 0 | Iteration: 280 | Classification loss: 0.38683 | Regression loss: 0.44614 | Running loss: 1.07415\n",
      "Epoch: 0 | Iteration: 283 | Classification loss: 0.32911 | Regression loss: 0.43726 | Running loss: 1.07122\n",
      "Epoch: 0 | Iteration: 284 | Classification loss: 0.66984 | Regression loss: 0.90706 | Running loss: 1.07599\n",
      "Epoch: 0 | Iteration: 286 | Classification loss: 0.34935 | Regression loss: 0.43607 | Running loss: 1.07328\n",
      "Epoch: 0 | Iteration: 292 | Classification loss: 0.34594 | Regression loss: 0.43755 | Running loss: 1.07059\n",
      "Epoch: 0 | Iteration: 293 | Classification loss: 0.27827 | Regression loss: 0.39075 | Running loss: 1.06691\n",
      "Epoch: 0 | Iteration: 299 | Classification loss: 0.43559 | Regression loss: 0.47806 | Running loss: 1.06552\n",
      "Epoch: 0 | Iteration: 300 | Classification loss: 0.55630 | Regression loss: 0.56694 | Running loss: 1.06604\n",
      "Epoch: 0 | Iteration: 301 | Classification loss: 0.47555 | Regression loss: 0.54903 | Running loss: 1.06567\n",
      "Epoch: 0 | Iteration: 302 | Classification loss: 0.81640 | Regression loss: 0.88038 | Running loss: 1.07125\n",
      "Epoch: 0 | Iteration: 303 | Classification loss: 0.45991 | Regression loss: 0.41848 | Running loss: 1.06956\n",
      "Epoch: 0 | Iteration: 304 | Classification loss: 0.45931 | Regression loss: 0.46378 | Running loss: 1.06829\n",
      "Epoch: 0 | Iteration: 305 | Classification loss: 0.39457 | Regression loss: 0.50148 | Running loss: 1.06680\n",
      "Epoch: 0 | Iteration: 306 | Classification loss: 0.74178 | Regression loss: 0.92495 | Running loss: 1.07193\n",
      "Epoch: 0 | Iteration: 307 | Classification loss: 0.26416 | Regression loss: 0.35187 | Running loss: 1.06807\n",
      "Epoch: 0 | Iteration: 309 | Classification loss: 0.41709 | Regression loss: 0.47928 | Running loss: 1.06662\n",
      "Epoch: 0 | Iteration: 311 | Classification loss: 0.28976 | Regression loss: 0.39430 | Running loss: 1.06343\n",
      "Epoch: 0 | Iteration: 314 | Classification loss: 0.45797 | Regression loss: 0.43954 | Running loss: 1.06206\n",
      "Epoch: 0 | Iteration: 315 | Classification loss: 0.28480 | Regression loss: 0.34809 | Running loss: 1.05855\n",
      "Epoch: 0 | Iteration: 319 | Classification loss: 0.34273 | Regression loss: 0.33563 | Running loss: 1.05545\n",
      "Epoch: 0 | Iteration: 324 | Classification loss: 0.30486 | Regression loss: 0.59754 | Running loss: 1.05422\n",
      "Epoch: 0 | Iteration: 326 | Classification loss: 0.33922 | Regression loss: 0.37791 | Running loss: 1.05152\n",
      "Epoch: 0 | Iteration: 329 | Classification loss: 0.39726 | Regression loss: 0.49588 | Running loss: 1.05027\n",
      "Epoch: 0 | Iteration: 330 | Classification loss: 0.43416 | Regression loss: 0.49247 | Running loss: 1.04929\n",
      "Epoch: 0 | Iteration: 332 | Classification loss: 0.46023 | Regression loss: 0.47178 | Running loss: 1.04838\n",
      "Epoch: 0 | Iteration: 333 | Classification loss: 0.35333 | Regression loss: 0.49754 | Running loss: 1.04685\n",
      "Epoch: 0 | Iteration: 337 | Classification loss: 0.93663 | Regression loss: 1.07857 | Running loss: 1.05429\n",
      "Epoch: 0 | Iteration: 349 | Classification loss: 0.30852 | Regression loss: 0.41729 | Running loss: 1.05179\n",
      "Epoch: 0 | Iteration: 350 | Classification loss: 0.49062 | Regression loss: 0.51427 | Running loss: 1.05143\n",
      "Epoch: 0 | Iteration: 352 | Classification loss: 0.39578 | Regression loss: 0.45068 | Running loss: 1.04989\n",
      "Epoch: 0 | Iteration: 358 | Classification loss: 0.49100 | Regression loss: 0.51334 | Running loss: 1.04955\n",
      "Epoch: 0 | Iteration: 362 | Classification loss: 0.33362 | Regression loss: 0.53129 | Running loss: 1.04818\n",
      "Epoch: 0 | Iteration: 363 | Classification loss: 0.28531 | Regression loss: 0.50371 | Running loss: 1.04628\n",
      "Epoch: 0 | Iteration: 365 | Classification loss: 0.43986 | Regression loss: 0.47868 | Running loss: 1.04534\n",
      "Epoch: 0 | Iteration: 368 | Classification loss: 0.30916 | Regression loss: 0.49164 | Running loss: 1.04357\n",
      "Epoch: 0 | Iteration: 370 | Classification loss: 0.30971 | Regression loss: 0.40547 | Running loss: 1.04121\n",
      "Epoch: 0 | Iteration: 371 | Classification loss: 0.72490 | Regression loss: 0.83850 | Running loss: 1.04494\n",
      "Epoch: 0 | Iteration: 378 | Classification loss: 0.26159 | Regression loss: 0.49571 | Running loss: 1.04290\n",
      "Epoch: 0 | Iteration: 379 | Classification loss: 0.35637 | Regression loss: 0.44300 | Running loss: 1.04119\n",
      "Epoch: 0 | Iteration: 382 | Classification loss: 0.68066 | Regression loss: 0.56162 | Running loss: 1.04259\n",
      "Epoch: 0 | Iteration: 389 | Classification loss: 0.35350 | Regression loss: 0.49514 | Running loss: 1.04124\n",
      "Epoch: 0 | Iteration: 394 | Classification loss: 0.27891 | Regression loss: 0.50586 | Running loss: 1.03948\n",
      "Epoch: 0 | Iteration: 395 | Classification loss: 0.71678 | Regression loss: 1.09733 | Running loss: 1.04478\n",
      "Epoch: 0 | Iteration: 396 | Classification loss: 0.37650 | Regression loss: 0.46044 | Running loss: 1.04337\n",
      "Epoch: 0 | Iteration: 398 | Classification loss: 0.43593 | Regression loss: 0.47517 | Running loss: 1.04247\n",
      "Epoch: 0 | Iteration: 399 | Classification loss: 0.25740 | Regression loss: 0.48888 | Running loss: 1.04049\n",
      "Epoch: 0 | Iteration: 402 | Classification loss: 0.40312 | Regression loss: 0.54723 | Running loss: 1.03989\n",
      "Epoch: 0 | Iteration: 403 | Classification loss: 0.39808 | Regression loss: 0.51756 | Running loss: 1.03906\n",
      "Epoch: 0 | Iteration: 409 | Classification loss: 0.62024 | Regression loss: 0.86484 | Running loss: 1.04200\n",
      "Epoch: 0 | Iteration: 411 | Classification loss: 0.29345 | Regression loss: 0.42634 | Running loss: 1.03989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Iteration: 412 | Classification loss: 0.35486 | Regression loss: 0.44257 | Running loss: 1.03832\n",
      "Epoch: 0 | Iteration: 414 | Classification loss: 0.31823 | Regression loss: 0.43963 | Running loss: 1.03651\n",
      "Epoch: 0 | Iteration: 418 | Classification loss: 0.40337 | Regression loss: 0.48387 | Running loss: 1.03555\n",
      "Epoch: 0 | Iteration: 419 | Classification loss: 0.37875 | Regression loss: 0.46550 | Running loss: 1.03433\n",
      "Epoch: 0 | Iteration: 420 | Classification loss: 0.46582 | Regression loss: 0.52533 | Running loss: 1.03406\n",
      "Epoch: 0 | Iteration: 425 | Classification loss: 0.33822 | Regression loss: 0.42810 | Running loss: 1.03237\n",
      "Epoch: 0 | Iteration: 434 | Classification loss: 0.49378 | Regression loss: 0.49271 | Running loss: 1.03209\n",
      "Epoch: 0 | Iteration: 435 | Classification loss: 0.34185 | Regression loss: 0.46733 | Running loss: 1.03070\n",
      "Epoch: 0 | Iteration: 436 | Classification loss: 0.31849 | Regression loss: 0.45445 | Running loss: 1.02911\n",
      "Epoch: 0 | Iteration: 437 | Classification loss: 0.31052 | Regression loss: 0.32367 | Running loss: 1.02669\n",
      "Epoch: 0 | Iteration: 439 | Classification loss: 0.35666 | Regression loss: 0.48256 | Running loss: 1.02555\n",
      "Epoch: 0 | Iteration: 443 | Classification loss: 0.30473 | Regression loss: 0.47347 | Running loss: 1.02405\n",
      "Epoch: 0 | Iteration: 445 | Classification loss: 0.31495 | Regression loss: 0.46348 | Running loss: 1.02257\n",
      "Epoch: 0 | Iteration: 447 | Classification loss: 0.26975 | Regression loss: 0.50728 | Running loss: 1.02110\n",
      "Epoch: 0 | Iteration: 449 | Classification loss: 0.33408 | Regression loss: 0.47675 | Running loss: 1.01985\n",
      "Epoch: 0 | Iteration: 450 | Classification loss: 0.37167 | Regression loss: 0.51483 | Running loss: 1.01906\n",
      "Epoch: 0 | Iteration: 456 | Classification loss: 0.30100 | Regression loss: 0.46039 | Running loss: 1.01754\n",
      "Epoch: 0 | Iteration: 458 | Classification loss: 0.34520 | Regression loss: 0.48463 | Running loss: 1.01644\n",
      "Epoch: 0 | Iteration: 463 | Classification loss: 0.30822 | Regression loss: 0.49914 | Running loss: 1.01523\n",
      "Epoch: 0 | Iteration: 465 | Classification loss: 0.24131 | Regression loss: 0.46413 | Running loss: 1.01344\n",
      "Epoch: 0 | Iteration: 466 | Classification loss: 0.35950 | Regression loss: 0.46254 | Running loss: 1.01234\n",
      "Epoch: 0 | Iteration: 467 | Classification loss: 0.45057 | Regression loss: 0.51815 | Running loss: 1.01209\n",
      "Epoch: 0 | Iteration: 469 | Classification loss: 0.71086 | Regression loss: 1.00963 | Running loss: 1.01611\n",
      "Epoch: 0 | Iteration: 472 | Classification loss: 0.36410 | Regression loss: 0.45233 | Running loss: 1.01498\n",
      "Epoch: 0 | Iteration: 477 | Classification loss: 0.64224 | Regression loss: 0.96690 | Running loss: 1.01832\n",
      "Epoch: 0 | Iteration: 478 | Classification loss: 0.47369 | Regression loss: 0.35982 | Running loss: 1.01729\n",
      "Epoch: 0 | Iteration: 483 | Classification loss: 0.31997 | Regression loss: 0.42056 | Running loss: 1.01575\n",
      "Epoch: 0 | Iteration: 491 | Classification loss: 0.31652 | Regression loss: 0.47144 | Running loss: 1.01449\n",
      "Epoch: 0 | Iteration: 493 | Classification loss: 0.74078 | Regression loss: 0.97963 | Running loss: 1.01837\n",
      "Epoch: 0 | Iteration: 506 | Classification loss: 0.27865 | Regression loss: 0.50906 | Running loss: 1.01711\n",
      "Epoch: 0 | Iteration: 509 | Classification loss: 0.28147 | Regression loss: 0.42425 | Running loss: 1.01542\n",
      "Epoch: 0 | Iteration: 510 | Classification loss: 0.29472 | Regression loss: 0.49954 | Running loss: 1.01422\n",
      "Epoch: 0 | Iteration: 514 | Classification loss: 0.26208 | Regression loss: 0.49965 | Running loss: 1.01287\n",
      "Epoch: 0 | Iteration: 515 | Classification loss: 0.60610 | Regression loss: 0.91938 | Running loss: 1.01561\n",
      "Epoch: 0 | Iteration: 519 | Classification loss: 0.28968 | Regression loss: 0.49089 | Running loss: 1.01436\n",
      "Epoch: 0 | Iteration: 526 | Classification loss: 0.46537 | Regression loss: 0.59097 | Running loss: 1.01458\n",
      "Epoch: 0 | Iteration: 527 | Classification loss: 0.30594 | Regression loss: 0.41251 | Running loss: 1.01302\n",
      "Epoch: 0 | Iteration: 529 | Classification loss: 0.23003 | Regression loss: 0.42867 | Running loss: 1.01117\n",
      "Epoch: 0 | Iteration: 530 | Classification loss: 0.62172 | Regression loss: 1.07555 | Running loss: 1.01474\n",
      "Epoch: 0 | Iteration: 534 | Classification loss: 0.30870 | Regression loss: 0.58273 | Running loss: 1.01410\n",
      "Epoch: 0 | Iteration: 536 | Classification loss: 0.31423 | Regression loss: 0.45190 | Running loss: 1.01282\n",
      "Epoch: 0 | Iteration: 537 | Classification loss: 0.55412 | Regression loss: 0.57586 | Running loss: 1.01342\n",
      "Epoch: 0 | Iteration: 538 | Classification loss: 0.27114 | Regression loss: 0.41115 | Running loss: 1.01173\n",
      "Epoch: 0 | Iteration: 544 | Classification loss: 0.31159 | Regression loss: 0.43197 | Running loss: 1.01037\n",
      "Epoch: 0 | Iteration: 547 | Classification loss: 0.39276 | Regression loss: 0.56685 | Running loss: 1.01012\n",
      "Epoch: 0 | Iteration: 548 | Classification loss: 0.24887 | Regression loss: 0.39190 | Running loss: 1.00826\n",
      "Epoch: 0 | Iteration: 551 | Classification loss: 0.32331 | Regression loss: 0.50510 | Running loss: 1.00736\n",
      "Epoch: 0 | Iteration: 553 | Classification loss: 0.36837 | Regression loss: 0.43725 | Running loss: 1.00636\n",
      "Epoch: 0 | Iteration: 554 | Classification loss: 0.54663 | Regression loss: 0.55964 | Running loss: 1.00685\n",
      "Epoch: 0 | Iteration: 556 | Classification loss: 0.31448 | Regression loss: 0.55445 | Running loss: 1.00617\n",
      "Epoch: 0 | Iteration: 562 | Classification loss: 0.35262 | Regression loss: 0.56499 | Running loss: 1.00574\n",
      "Epoch: 0 | Iteration: 565 | Classification loss: 0.25135 | Regression loss: 0.51546 | Running loss: 1.00457\n",
      "Epoch: 0 | Iteration: 567 | Classification loss: 0.23413 | Regression loss: 0.39612 | Running loss: 1.00276\n",
      "Epoch: 0 | Iteration: 568 | Classification loss: 0.29328 | Regression loss: 0.46072 | Running loss: 1.00155\n",
      "Epoch: 0 | Iteration: 569 | Classification loss: 0.48646 | Regression loss: 0.68017 | Running loss: 1.00235\n",
      "Epoch: 0 | Iteration: 571 | Classification loss: 0.27947 | Regression loss: 0.40584 | Running loss: 1.00083\n",
      "Epoch: 0 | Iteration: 573 | Classification loss: 0.26948 | Regression loss: 0.52685 | Running loss: 0.99986\n",
      "Epoch: 0 | Iteration: 574 | Classification loss: 0.29212 | Regression loss: 0.55688 | Running loss: 0.99914\n",
      "Epoch: 0 | Iteration: 577 | Classification loss: 0.29821 | Regression loss: 0.47173 | Running loss: 0.99806\n",
      "Epoch: 0 | Iteration: 580 | Classification loss: 0.30193 | Regression loss: 0.57413 | Running loss: 0.99749\n",
      "Epoch: 0 | Iteration: 583 | Classification loss: 0.23137 | Regression loss: 0.35685 | Running loss: 0.99558\n",
      "Epoch: 0 | Iteration: 588 | Classification loss: 0.40853 | Regression loss: 0.48070 | Running loss: 0.99508\n",
      "Epoch: 0 | Iteration: 591 | Classification loss: 0.81654 | Regression loss: 0.91395 | Running loss: 0.99849\n",
      "Epoch: 0 | Iteration: 592 | Classification loss: 0.30757 | Regression loss: 0.52039 | Running loss: 0.99770\n",
      "Epoch: 0 | Iteration: 596 | Classification loss: 0.31619 | Regression loss: 0.48879 | Running loss: 0.99682\n",
      "Epoch: 0 | Iteration: 601 | Classification loss: 0.51699 | Regression loss: 0.56517 | Running loss: 0.99721\n",
      "Epoch: 0 | Iteration: 603 | Classification loss: 0.29429 | Regression loss: 0.46714 | Running loss: 0.99613\n",
      "Epoch: 0 | Iteration: 605 | Classification loss: 0.30033 | Regression loss: 0.44585 | Running loss: 0.99500\n",
      "Epoch: 0 | Iteration: 606 | Classification loss: 0.27999 | Regression loss: 0.51201 | Running loss: 0.99409\n",
      "Epoch: 0 | Iteration: 607 | Classification loss: 0.50819 | Regression loss: 0.42287 | Running loss: 0.99381\n",
      "Epoch: 0 | Iteration: 610 | Classification loss: 0.34560 | Regression loss: 0.60584 | Running loss: 0.99362\n",
      "Epoch: 0 | Iteration: 617 | Classification loss: 0.24143 | Regression loss: 0.46341 | Running loss: 0.99233\n",
      "Epoch: 0 | Iteration: 619 | Classification loss: 0.49968 | Regression loss: 0.54692 | Running loss: 0.99257\n",
      "Epoch: 0 | Iteration: 620 | Classification loss: 0.53737 | Regression loss: 1.09842 | Running loss: 0.99541\n",
      "Epoch: 0 | Iteration: 623 | Classification loss: 0.43986 | Regression loss: 0.48947 | Running loss: 0.99512\n",
      "Epoch: 0 | Iteration: 626 | Classification loss: 0.72217 | Regression loss: 0.92948 | Running loss: 0.99798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Iteration: 629 | Classification loss: 0.34020 | Regression loss: 0.51464 | Running loss: 0.99736\n",
      "Epoch: 0 | Iteration: 631 | Classification loss: 0.28340 | Regression loss: 0.51533 | Running loss: 0.99650\n",
      "Epoch: 0 | Iteration: 634 | Classification loss: 0.36263 | Regression loss: 0.44149 | Running loss: 0.99567\n",
      "Epoch: 0 | Iteration: 637 | Classification loss: 0.33044 | Regression loss: 0.55334 | Running loss: 0.99519\n",
      "Epoch: 0 | Iteration: 643 | Classification loss: 0.30447 | Regression loss: 0.47118 | Running loss: 0.99425\n",
      "Epoch: 0 | Iteration: 644 | Classification loss: 0.58005 | Regression loss: 0.47810 | Running loss: 0.99453\n",
      "Epoch: 0 | Iteration: 645 | Classification loss: 0.32320 | Regression loss: 0.49470 | Running loss: 0.99378\n",
      "Epoch: 0 | Iteration: 650 | Classification loss: 0.34573 | Regression loss: 0.28763 | Running loss: 0.99226\n",
      "Epoch: 0 | Iteration: 651 | Classification loss: 0.25183 | Regression loss: 0.46542 | Running loss: 0.99110\n",
      "Epoch: 0 | Iteration: 652 | Classification loss: 0.37049 | Regression loss: 0.49995 | Running loss: 0.99060\n",
      "Epoch: 0 | Iteration: 653 | Classification loss: 0.25345 | Regression loss: 0.52777 | Running loss: 0.98972\n",
      "Epoch: 0 | Iteration: 655 | Classification loss: 0.24310 | Regression loss: 0.41969 | Running loss: 0.98837\n",
      "Epoch: 0 | Iteration: 656 | Classification loss: 0.23195 | Regression loss: 0.43346 | Running loss: 0.98703\n",
      "Epoch: 0 | Iteration: 657 | Classification loss: 0.29242 | Regression loss: 0.47897 | Running loss: 0.98615\n",
      "Epoch: 0 | Iteration: 660 | Classification loss: 0.24616 | Regression loss: 0.42782 | Running loss: 0.98487\n",
      "Epoch: 0 | Iteration: 661 | Classification loss: 0.23332 | Regression loss: 0.43057 | Running loss: 0.98356\n",
      "Epoch: 0 | Iteration: 663 | Classification loss: 0.22205 | Regression loss: 0.45065 | Running loss: 0.98229\n",
      "Epoch: 0 | Iteration: 664 | Classification loss: 0.23839 | Regression loss: 0.43528 | Running loss: 0.98104\n",
      "Epoch: 0 | Iteration: 665 | Classification loss: 0.36895 | Regression loss: 0.53974 | Running loss: 0.98075\n",
      "Epoch: 0 | Iteration: 670 | Classification loss: 0.33497 | Regression loss: 0.56528 | Running loss: 0.98043\n",
      "Epoch: 0 | Iteration: 676 | Classification loss: 0.41522 | Regression loss: 0.49407 | Running loss: 0.98014\n",
      "Epoch: 0 | Iteration: 678 | Classification loss: 0.26167 | Regression loss: 0.41949 | Running loss: 0.97895\n",
      "Epoch: 0 | Iteration: 683 | Classification loss: 0.29491 | Regression loss: 0.49029 | Running loss: 0.97818\n",
      "Epoch: 0 | Iteration: 685 | Classification loss: 0.39268 | Regression loss: 0.53638 | Running loss: 0.97799\n",
      "Epoch: 0 | Iteration: 687 | Classification loss: 0.30104 | Regression loss: 0.43958 | Running loss: 0.97705\n",
      "Epoch: 0 | Iteration: 688 | Classification loss: 0.25283 | Regression loss: 0.43189 | Running loss: 0.97591\n",
      "Epoch: 0 | Iteration: 691 | Classification loss: 0.25999 | Regression loss: 0.45188 | Running loss: 0.97488\n",
      "Epoch: 0 | Iteration: 693 | Classification loss: 0.81050 | Regression loss: 0.96050 | Running loss: 0.97797\n",
      "Epoch: 0 | Iteration: 697 | Classification loss: 0.23845 | Regression loss: 0.45939 | Running loss: 0.97689\n",
      "Epoch: 0 | Iteration: 703 | Classification loss: 0.37190 | Regression loss: 0.49902 | Running loss: 0.97648\n",
      "Epoch: 0 | Iteration: 706 | Classification loss: 0.35618 | Regression loss: 0.48646 | Running loss: 0.97596\n",
      "Epoch: 0 | Iteration: 717 | Classification loss: 0.50090 | Regression loss: 0.45921 | Running loss: 0.97590\n",
      "Epoch: 0 | Iteration: 719 | Classification loss: 0.33907 | Regression loss: 0.61364 | Running loss: 0.97582\n",
      "Epoch: 0 | Iteration: 720 | Classification loss: 0.27299 | Regression loss: 0.50765 | Running loss: 0.97507\n",
      "Epoch: 0 | Iteration: 722 | Classification loss: 0.27549 | Regression loss: 0.49535 | Running loss: 0.97430\n",
      "Epoch: 0 | Iteration: 723 | Classification loss: 0.28178 | Regression loss: 0.52535 | Running loss: 0.97367\n",
      "Epoch: 0 | Iteration: 724 | Classification loss: 0.30446 | Regression loss: 0.45338 | Running loss: 0.97286\n",
      "Epoch: 0 | Iteration: 725 | Classification loss: 0.27174 | Regression loss: 0.42885 | Running loss: 0.97184\n",
      "Epoch: 0 | Iteration: 727 | Classification loss: 0.32189 | Regression loss: 0.55521 | Running loss: 0.97148\n",
      "Epoch: 0 | Iteration: 728 | Classification loss: 0.25035 | Regression loss: 0.46170 | Running loss: 0.97052\n",
      "Epoch: 0 | Iteration: 729 | Classification loss: 0.19995 | Regression loss: 0.36805 | Running loss: 0.96903\n",
      "Epoch: 0 | Iteration: 730 | Classification loss: 0.22329 | Regression loss: 0.45249 | Running loss: 0.96795\n",
      "Epoch: 0 | Iteration: 731 | Classification loss: 0.22558 | Regression loss: 0.44672 | Running loss: 0.96686\n",
      "Epoch: 0 | Iteration: 734 | Classification loss: 0.25461 | Regression loss: 0.45173 | Running loss: 0.96591\n",
      "Epoch: 0 | Iteration: 740 | Classification loss: 0.29456 | Regression loss: 0.47343 | Running loss: 0.96518\n",
      "Epoch: 0 | Iteration: 741 | Classification loss: 0.39254 | Regression loss: 0.45860 | Running loss: 0.96477\n",
      "Epoch: 0 | Iteration: 743 | Classification loss: 0.53738 | Regression loss: 0.84786 | Running loss: 0.96629\n",
      "Epoch: 0 | Iteration: 744 | Classification loss: 0.44297 | Regression loss: 0.54752 | Running loss: 0.96638\n",
      "Epoch: 0 | Iteration: 745 | Classification loss: 0.33245 | Regression loss: 0.41590 | Running loss: 0.96560\n",
      "Epoch: 0 | Iteration: 748 | Classification loss: 0.32151 | Regression loss: 0.42748 | Running loss: 0.96482\n",
      "Epoch: 0 | Iteration: 749 | Classification loss: 0.41436 | Regression loss: 0.53940 | Running loss: 0.96478\n",
      "Epoch: 0 | Iteration: 752 | Classification loss: 0.30703 | Regression loss: 0.48531 | Running loss: 0.96417\n",
      "Epoch: 0 | Iteration: 755 | Classification loss: 0.29070 | Regression loss: 0.54369 | Running loss: 0.96371\n",
      "Epoch: 0 | Iteration: 756 | Classification loss: 0.30403 | Regression loss: 0.47631 | Running loss: 0.96306\n",
      "Epoch: 0 | Iteration: 757 | Classification loss: 0.31263 | Regression loss: 0.46865 | Running loss: 0.96242\n",
      "Epoch: 0 | Iteration: 759 | Classification loss: 0.44708 | Regression loss: 0.51229 | Running loss: 0.96241\n",
      "Epoch: 0 | Iteration: 760 | Classification loss: 0.31051 | Regression loss: 0.51265 | Running loss: 0.96192\n",
      "Epoch: 0 | Iteration: 763 | Classification loss: 0.28538 | Regression loss: 0.51442 | Running loss: 0.96136\n",
      "Epoch: 0 | Iteration: 765 | Classification loss: 0.26173 | Regression loss: 0.44324 | Running loss: 0.96046\n",
      "Epoch: 0 | Iteration: 766 | Classification loss: 0.25641 | Regression loss: 0.53337 | Running loss: 0.95987\n",
      "Epoch: 0 | Iteration: 769 | Classification loss: 0.24159 | Regression loss: 0.41395 | Running loss: 0.95882\n",
      "Epoch: 0 | Iteration: 770 | Classification loss: 0.25993 | Regression loss: 0.46930 | Running loss: 0.95804\n",
      "Epoch: 0 | Iteration: 771 | Classification loss: 0.32420 | Regression loss: 0.55937 | Running loss: 0.95778\n",
      "Epoch: 0 | Iteration: 773 | Classification loss: 0.19165 | Regression loss: 0.42512 | Running loss: 0.95662\n",
      "Epoch: 0 | Iteration: 775 | Classification loss: 0.30032 | Regression loss: 0.40688 | Running loss: 0.95577\n",
      "Epoch: 0 | Iteration: 780 | Classification loss: 0.24077 | Regression loss: 0.50450 | Running loss: 0.95506\n",
      "Epoch: 0 | Iteration: 782 | Classification loss: 0.23971 | Regression loss: 0.46066 | Running loss: 0.95419\n",
      "Epoch: 0 | Iteration: 783 | Classification loss: 0.53077 | Regression loss: 0.97049 | Running loss: 0.95604\n",
      "Epoch: 0 | Iteration: 786 | Classification loss: 0.30671 | Regression loss: 0.42444 | Running loss: 0.95528\n",
      "Epoch: 0 | Iteration: 787 | Classification loss: 0.29606 | Regression loss: 0.40544 | Running loss: 0.95443\n",
      "Epoch: 0 | Iteration: 791 | Classification loss: 0.30981 | Regression loss: 0.60652 | Running loss: 0.95431\n",
      "Epoch: 0 | Iteration: 793 | Classification loss: 0.21911 | Regression loss: 0.45184 | Running loss: 0.95336\n",
      "Epoch: 0 | Iteration: 797 | Classification loss: 0.27685 | Regression loss: 0.51261 | Running loss: 0.95282\n",
      "Epoch: 0 | Iteration: 799 | Classification loss: 0.31662 | Regression loss: 0.45982 | Running loss: 0.95224\n",
      "Epoch: 0 | Iteration: 802 | Classification loss: 0.21876 | Regression loss: 0.46719 | Running loss: 0.95136\n",
      "Epoch: 0 | Iteration: 806 | Classification loss: 0.51257 | Regression loss: 0.56515 | Running loss: 0.95178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Iteration: 808 | Classification loss: 0.34208 | Regression loss: 0.45071 | Running loss: 0.95126\n",
      "Epoch: 0 | Iteration: 811 | Classification loss: 0.22443 | Regression loss: 0.41399 | Running loss: 0.95024\n",
      "Epoch: 0 | Iteration: 812 | Classification loss: 0.48497 | Regression loss: 0.89305 | Running loss: 0.95163\n",
      "Epoch: 0 | Iteration: 814 | Classification loss: 0.49105 | Regression loss: 0.46178 | Running loss: 0.95163\n",
      "Epoch: 0 | Iteration: 815 | Classification loss: 0.28963 | Regression loss: 0.59777 | Running loss: 0.95143\n",
      "Epoch: 0 | Iteration: 821 | Classification loss: 0.36703 | Regression loss: 0.41208 | Running loss: 0.95087\n",
      "Epoch: 0 | Iteration: 822 | Classification loss: 0.23069 | Regression loss: 0.50244 | Running loss: 0.95017\n",
      "Epoch: 0 | Iteration: 826 | Classification loss: 0.20716 | Regression loss: 0.44195 | Running loss: 0.94921\n",
      "Epoch: 0 | Iteration: 830 | Classification loss: 0.24900 | Regression loss: 0.52626 | Running loss: 0.94866\n",
      "Epoch: 0 | Iteration: 831 | Classification loss: 0.23122 | Regression loss: 0.49281 | Running loss: 0.94794\n",
      "Epoch: 0 | Iteration: 832 | Classification loss: 0.30873 | Regression loss: 0.57000 | Running loss: 0.94773\n",
      "Epoch: 0 | Iteration: 835 | Classification loss: 0.25283 | Regression loss: 0.44348 | Running loss: 0.94693\n",
      "Epoch: 0 | Iteration: 839 | Classification loss: 0.53981 | Regression loss: 1.01605 | Running loss: 0.94885\n",
      "Epoch: 0 | Iteration: 843 | Classification loss: 0.32180 | Regression loss: 0.50693 | Running loss: 0.94847\n",
      "Epoch: 0 | Iteration: 847 | Classification loss: 0.36324 | Regression loss: 0.44488 | Running loss: 0.94803\n",
      "Epoch: 0 | Iteration: 848 | Classification loss: 0.61314 | Regression loss: 0.98204 | Running loss: 0.95005\n",
      "Epoch: 0 | Iteration: 849 | Classification loss: 0.29296 | Regression loss: 0.52954 | Running loss: 0.94965\n",
      "Epoch: 0 | Iteration: 853 | Classification loss: 0.21034 | Regression loss: 0.43038 | Running loss: 0.94870\n",
      "Epoch: 0 | Iteration: 855 | Classification loss: 0.25559 | Regression loss: 0.48641 | Running loss: 0.94806\n",
      "Epoch: 0 | Iteration: 857 | Classification loss: 0.31920 | Regression loss: 0.49127 | Running loss: 0.94763\n",
      "Epoch: 0 | Iteration: 858 | Classification loss: 0.22735 | Regression loss: 0.42320 | Running loss: 0.94672\n",
      "Epoch: 0 | Iteration: 863 | Classification loss: 0.23083 | Regression loss: 0.44637 | Running loss: 0.94590\n",
      "Epoch: 0 | Iteration: 866 | Classification loss: 0.21506 | Regression loss: 0.47148 | Running loss: 0.94511\n",
      "Epoch: 0 | Iteration: 867 | Classification loss: 0.26063 | Regression loss: 0.47341 | Running loss: 0.94447\n",
      "Epoch: 0 | Iteration: 868 | Classification loss: 0.19535 | Regression loss: 0.44643 | Running loss: 0.94355\n",
      "Epoch: 0 | Iteration: 870 | Classification loss: 0.56926 | Regression loss: 0.99477 | Running loss: 0.94542\n",
      "Epoch: 0 | Iteration: 877 | Classification loss: 0.25858 | Regression loss: 0.48532 | Running loss: 0.94482\n",
      "Epoch: 0 | Iteration: 882 | Classification loss: 0.18886 | Regression loss: 0.47453 | Running loss: 0.94397\n",
      "Epoch: 0 | Iteration: 883 | Classification loss: 0.30673 | Regression loss: 0.50202 | Running loss: 0.94357\n",
      "Epoch: 0 | Iteration: 884 | Classification loss: 0.14532 | Regression loss: 0.38445 | Running loss: 0.94233\n",
      "Epoch: 0 | Iteration: 887 | Classification loss: 0.20319 | Regression loss: 0.44088 | Running loss: 0.94144\n",
      "Epoch: 0 | Iteration: 892 | Classification loss: 0.39599 | Regression loss: 0.49977 | Running loss: 0.94131\n",
      "Epoch: 0 | Iteration: 893 | Classification loss: 0.36249 | Regression loss: 0.49187 | Running loss: 0.94105\n",
      "Epoch: 0 | Iteration: 900 | Classification loss: 0.28900 | Regression loss: 0.50000 | Running loss: 0.94060\n",
      "Epoch: 0 | Iteration: 902 | Classification loss: 0.28755 | Regression loss: 0.53572 | Running loss: 0.94026\n",
      "Epoch: 0 | Iteration: 904 | Classification loss: 0.20233 | Regression loss: 0.39357 | Running loss: 0.93925\n",
      "Epoch: 0 | Iteration: 908 | Classification loss: 0.54548 | Regression loss: 0.93146 | Running loss: 0.94082\n",
      "Epoch: 0 | Iteration: 909 | Classification loss: 0.21091 | Regression loss: 0.49121 | Running loss: 0.94012\n",
      "Epoch: 0 | Iteration: 917 | Classification loss: 0.26976 | Regression loss: 0.51865 | Running loss: 0.93968\n",
      "Epoch: 0 | Iteration: 919 | Classification loss: 0.33074 | Regression loss: 0.60854 | Running loss: 0.93968\n",
      "Epoch: 0 | Iteration: 923 | Classification loss: 0.66352 | Regression loss: 1.14066 | Running loss: 0.94218\n",
      "Epoch: 0 | Iteration: 926 | Classification loss: 0.27859 | Regression loss: 0.38901 | Running loss: 0.94139\n",
      "Epoch: 0 | Iteration: 933 | Classification loss: 0.21643 | Regression loss: 0.39765 | Running loss: 0.94045\n",
      "Epoch: 0 | Iteration: 934 | Classification loss: 0.63729 | Regression loss: 0.95522 | Running loss: 0.94232\n",
      "Epoch: 0 | Iteration: 937 | Classification loss: 0.20773 | Regression loss: 0.46855 | Running loss: 0.94156\n",
      "Epoch: 0 | Iteration: 939 | Classification loss: 0.17909 | Regression loss: 0.44373 | Running loss: 0.94065\n",
      "Epoch: 0 | Iteration: 947 | Classification loss: 0.20364 | Regression loss: 0.47109 | Running loss: 0.93989\n",
      "Epoch: 0 | Iteration: 948 | Classification loss: 0.17718 | Regression loss: 0.49976 | Running loss: 0.93915\n",
      "Epoch: 0 | Iteration: 952 | Classification loss: 0.19048 | Regression loss: 0.44999 | Running loss: 0.93830\n",
      "Epoch: 0 | Iteration: 958 | Classification loss: 0.76763 | Regression loss: 0.99133 | Running loss: 0.94062\n",
      "Epoch: 0 | Iteration: 959 | Classification loss: 0.18011 | Regression loss: 0.46665 | Running loss: 0.93979\n",
      "Epoch: 0 | Iteration: 962 | Classification loss: 0.17732 | Regression loss: 0.41928 | Running loss: 0.93883\n",
      "Epoch: 0 | Iteration: 963 | Classification loss: 0.52306 | Regression loss: 0.94607 | Running loss: 0.94031\n",
      "Epoch: 0 | Iteration: 967 | Classification loss: 0.26600 | Regression loss: 0.49648 | Running loss: 0.93982\n",
      "Epoch: 0 | Iteration: 970 | Classification loss: 0.42391 | Regression loss: 0.49524 | Running loss: 0.93976\n",
      "Epoch: 0 | Iteration: 971 | Classification loss: 0.15400 | Regression loss: 0.40027 | Running loss: 0.93869\n",
      "Epoch: 0 | Iteration: 974 | Classification loss: 0.50279 | Regression loss: 0.90835 | Running loss: 0.94000\n",
      "Epoch: 0 | Iteration: 976 | Classification loss: 0.33650 | Regression loss: 0.48171 | Running loss: 0.93966\n",
      "Epoch: 0 | Iteration: 977 | Classification loss: 0.39557 | Regression loss: 0.45254 | Running loss: 0.93941\n",
      "Epoch: 0 | Iteration: 981 | Classification loss: 0.19672 | Regression loss: 0.41849 | Running loss: 0.93852\n",
      "Epoch: 0 | Iteration: 982 | Classification loss: 0.37759 | Regression loss: 0.55437 | Running loss: 0.93850\n",
      "Epoch: 0 | Iteration: 983 | Classification loss: 0.24054 | Regression loss: 0.43859 | Running loss: 0.93780\n",
      "Epoch: 0 | Iteration: 988 | Classification loss: 0.18735 | Regression loss: 0.48762 | Running loss: 0.93708\n",
      "Epoch: 0 | Iteration: 997 | Classification loss: 0.15555 | Regression loss: 0.39487 | Running loss: 0.93603\n",
      "Epoch: 0 | Iteration: 998 | Classification loss: 0.30163 | Regression loss: 0.53578 | Running loss: 0.93577\n",
      "Epoch: 0 | Iteration: 999 | Classification loss: 0.20846 | Regression loss: 0.41844 | Running loss: 0.93493\n",
      "Epoch: 0 | Iteration: 1004 | Classification loss: 0.18763 | Regression loss: 0.41986 | Running loss: 0.93405\n",
      "Epoch: 0 | Iteration: 1008 | Classification loss: 0.17807 | Regression loss: 0.44050 | Running loss: 0.93321\n",
      "Epoch: 0 | Iteration: 1010 | Classification loss: 0.17249 | Regression loss: 0.48109 | Running loss: 0.93246\n",
      "Epoch: 0 | Iteration: 1013 | Classification loss: 0.32891 | Regression loss: 0.55748 | Running loss: 0.93234\n",
      "Epoch: 0 | Iteration: 1017 | Classification loss: 0.33553 | Regression loss: 0.49255 | Running loss: 0.93206\n",
      "Epoch: 0 | Iteration: 1020 | Classification loss: 0.18866 | Regression loss: 0.51114 | Running loss: 0.93144\n",
      "Epoch: 0 | Iteration: 1023 | Classification loss: 0.27088 | Regression loss: 0.55477 | Running loss: 0.93116\n",
      "Epoch: 0 | Iteration: 1025 | Classification loss: 0.25853 | Regression loss: 0.42328 | Running loss: 0.93051\n",
      "Epoch: 0 | Iteration: 1033 | Classification loss: 0.23205 | Regression loss: 0.49135 | Running loss: 0.92996\n",
      "Epoch: 0 | Iteration: 1034 | Classification loss: 0.20355 | Regression loss: 0.39028 | Running loss: 0.92908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Iteration: 1036 | Classification loss: 0.17638 | Regression loss: 0.44807 | Running loss: 0.92828\n",
      "Epoch: 0 | Iteration: 1038 | Classification loss: 0.84904 | Regression loss: 0.96636 | Running loss: 0.93060\n",
      "Epoch: 0 | Iteration: 1040 | Classification loss: 0.19834 | Regression loss: 0.45910 | Running loss: 0.92989\n",
      "Epoch: 0 | Iteration: 1041 | Classification loss: 0.30273 | Regression loss: 0.51292 | Running loss: 0.92959\n",
      "Epoch: 0 | Iteration: 1042 | Classification loss: 0.23482 | Regression loss: 0.50614 | Running loss: 0.92910\n",
      "Epoch: 0 | Iteration: 1043 | Classification loss: 0.18692 | Regression loss: 0.42684 | Running loss: 0.92829\n",
      "Epoch: 0 | Iteration: 1044 | Classification loss: 0.15901 | Regression loss: 0.47530 | Running loss: 0.92753\n",
      "Epoch: 0 | Iteration: 1050 | Classification loss: 0.23179 | Regression loss: 0.54894 | Running loss: 0.92715\n",
      "Epoch: 0 | Iteration: 1051 | Classification loss: 0.16844 | Regression loss: 0.44199 | Running loss: 0.92634\n",
      "Epoch: 0 | Iteration: 1052 | Classification loss: 0.34387 | Regression loss: 0.46620 | Running loss: 0.92604\n",
      "Epoch: 0 | Iteration: 1054 | Classification loss: 0.45629 | Regression loss: 0.47720 | Running loss: 0.92606\n",
      "Epoch: 0 | Iteration: 1055 | Classification loss: 0.23247 | Regression loss: 0.47085 | Running loss: 0.92549\n",
      "Epoch: 0 | Iteration: 1057 | Classification loss: 0.53426 | Regression loss: 0.99773 | Running loss: 0.92703\n",
      "Epoch: 0 | Iteration: 1065 | Classification loss: 0.23448 | Regression loss: 0.42905 | Running loss: 0.92637\n",
      "Epoch: 0 | Iteration: 1067 | Classification loss: 0.38157 | Regression loss: 0.50544 | Running loss: 0.92627\n",
      "Epoch: 0 | Iteration: 1068 | Classification loss: 0.20459 | Regression loss: 0.40612 | Running loss: 0.92547\n",
      "Epoch: 0 | Iteration: 1069 | Classification loss: 0.27782 | Regression loss: 0.42363 | Running loss: 0.92491\n",
      "Epoch: 0 | Iteration: 1076 | Classification loss: 0.32948 | Regression loss: 0.53372 | Running loss: 0.92475\n",
      "Epoch: 0 | Iteration: 1077 | Classification loss: 0.21421 | Regression loss: 0.47093 | Running loss: 0.92416\n",
      "Epoch: 0 | Iteration: 1081 | Classification loss: 0.21948 | Regression loss: 0.42981 | Running loss: 0.92347\n",
      "Epoch: 0 | Iteration: 1082 | Classification loss: 0.19336 | Regression loss: 0.48804 | Running loss: 0.92287\n",
      "Epoch: 0 | Iteration: 1083 | Classification loss: 0.28131 | Regression loss: 0.48401 | Running loss: 0.92248\n",
      "Epoch: 0 | Iteration: 1085 | Classification loss: 0.33350 | Regression loss: 0.44054 | Running loss: 0.92211\n",
      "Epoch: 0 | Iteration: 1087 | Classification loss: 0.22084 | Regression loss: 0.40656 | Running loss: 0.92138\n",
      "Epoch: 0 | Iteration: 1090 | Classification loss: 0.46398 | Regression loss: 0.92225 | Running loss: 0.92253\n",
      "Epoch: 0 | Iteration: 1091 | Classification loss: 0.27503 | Regression loss: 0.35887 | Running loss: 0.92182\n",
      "Epoch: 0 | Iteration: 1092 | Classification loss: 0.26149 | Regression loss: 0.43473 | Running loss: 0.92126\n",
      "Epoch: 0 | Iteration: 1095 | Classification loss: 0.28704 | Regression loss: 0.47070 | Running loss: 0.92087\n",
      "Epoch: 0 | Iteration: 1104 | Classification loss: 0.31839 | Regression loss: 0.53520 | Running loss: 0.92070\n",
      "Epoch: 0 | Iteration: 1106 | Classification loss: 0.18002 | Regression loss: 0.46076 | Running loss: 0.92002\n",
      "Epoch: 0 | Iteration: 1108 | Classification loss: 0.31358 | Regression loss: 0.45222 | Running loss: 0.91965\n",
      "Epoch: 0 | Iteration: 1109 | Classification loss: 0.39200 | Regression loss: 0.48565 | Running loss: 0.91954\n",
      "Epoch: 0 | Iteration: 1111 | Classification loss: 0.43671 | Regression loss: 0.76446 | Running loss: 0.92022\n",
      "Epoch: 0 | Iteration: 1115 | Classification loss: 0.26526 | Regression loss: 0.46458 | Running loss: 0.91977\n",
      "Epoch: 0 | Iteration: 1117 | Classification loss: 0.27511 | Regression loss: 0.45435 | Running loss: 0.91931\n",
      "Epoch: 0 | Iteration: 1118 | Classification loss: 0.41173 | Regression loss: 0.81669 | Running loss: 0.92005\n",
      "Epoch: 0 | Iteration: 1119 | Classification loss: 0.26783 | Regression loss: 0.44905 | Running loss: 0.91956\n",
      "Epoch: 0 | Iteration: 1122 | Classification loss: 0.29077 | Regression loss: 0.46468 | Running loss: 0.91917\n",
      "Epoch: 0 | Iteration: 1127 | Classification loss: 0.24607 | Regression loss: 0.57390 | Running loss: 0.91894\n",
      "Epoch: 0 | Iteration: 1129 | Classification loss: 0.24900 | Regression loss: 0.50011 | Running loss: 0.91853\n",
      "Epoch: 0 | Iteration: 1132 | Classification loss: 0.50069 | Regression loss: 0.56837 | Running loss: 0.91889\n",
      "Epoch: 0 | Iteration: 1134 | Classification loss: 0.25452 | Regression loss: 0.43052 | Running loss: 0.91834\n",
      "Epoch: 0 | Iteration: 1135 | Classification loss: 0.20301 | Regression loss: 0.47714 | Running loss: 0.91777\n",
      "Epoch: 0 | Iteration: 1138 | Classification loss: 0.30735 | Regression loss: 0.47554 | Running loss: 0.91746\n",
      "Epoch: 0 | Iteration: 1139 | Classification loss: 0.23884 | Regression loss: 0.43078 | Running loss: 0.91687\n",
      "Epoch: 0 | Iteration: 1144 | Classification loss: 0.34391 | Regression loss: 0.49346 | Running loss: 0.91669\n",
      "Epoch: 0 | Iteration: 1145 | Classification loss: 0.30675 | Regression loss: 0.58683 | Running loss: 0.91663\n",
      "Epoch: 0 | Iteration: 1147 | Classification loss: 0.31564 | Regression loss: 0.44203 | Running loss: 0.91626\n",
      "Epoch: 0 | Iteration: 1148 | Classification loss: 0.24893 | Regression loss: 0.42742 | Running loss: 0.91571\n",
      "Epoch: 0 | Iteration: 1149 | Classification loss: 0.53254 | Regression loss: 1.01193 | Running loss: 0.91716\n",
      "Epoch: 0 | Iteration: 1151 | Classification loss: 0.24908 | Regression loss: 0.46721 | Running loss: 0.91670\n",
      "Epoch: 0 | Iteration: 1156 | Classification loss: 0.22315 | Regression loss: 0.43886 | Running loss: 0.91611\n",
      "Epoch: 0 | Iteration: 1157 | Classification loss: 0.21743 | Regression loss: 0.42293 | Running loss: 0.91548\n",
      "Epoch: 0 | Iteration: 1160 | Classification loss: 0.23323 | Regression loss: 0.45560 | Running loss: 0.91496\n",
      "Epoch: 0 | Iteration: 1161 | Classification loss: 0.44229 | Regression loss: 0.99973 | Running loss: 0.91616\n",
      "Epoch: 0 | Iteration: 1163 | Classification loss: 0.24874 | Regression loss: 0.60096 | Running loss: 0.91601\n",
      "Epoch: 0 | Iteration: 1166 | Classification loss: 0.19395 | Regression loss: 0.49236 | Running loss: 0.91549\n",
      "Epoch: 0 | Iteration: 1169 | Classification loss: 0.64594 | Regression loss: 0.98806 | Running loss: 0.91712\n",
      "Epoch: 0 | Iteration: 1172 | Classification loss: 0.27767 | Regression loss: 0.55276 | Running loss: 0.91693\n",
      "Epoch: 0 | Iteration: 1175 | Classification loss: 0.28483 | Regression loss: 0.44817 | Running loss: 0.91651\n",
      "Epoch: 0 | Iteration: 1176 | Classification loss: 0.26651 | Regression loss: 0.47571 | Running loss: 0.91612\n",
      "Epoch: 0 | Iteration: 1182 | Classification loss: 0.15584 | Regression loss: 0.46651 | Running loss: 0.91545\n",
      "Epoch: 0 | Iteration: 1185 | Classification loss: 0.57790 | Regression loss: 0.92029 | Running loss: 0.91677\n",
      "Epoch: 0 | Iteration: 1188 | Classification loss: 0.36279 | Regression loss: 0.43009 | Running loss: 0.91649\n",
      "Epoch: 0 | Iteration: 1190 | Classification loss: 0.23196 | Regression loss: 0.39281 | Running loss: 0.91583\n",
      "Epoch: 0 | Iteration: 1192 | Classification loss: 0.31501 | Regression loss: 0.44270 | Running loss: 0.91548\n",
      "Epoch: 0 | Iteration: 1194 | Classification loss: 0.20110 | Regression loss: 0.48540 | Running loss: 0.91497\n",
      "Epoch: 0 | Iteration: 1196 | Classification loss: 0.44509 | Regression loss: 0.89560 | Running loss: 0.91592\n",
      "Epoch: 0 | Iteration: 1197 | Classification loss: 0.21810 | Regression loss: 0.40365 | Running loss: 0.91526\n",
      "Epoch: 0 | Iteration: 1199 | Classification loss: 0.32147 | Regression loss: 0.45088 | Running loss: 0.91495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/krf/anaconda/anaconda3/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/data/krf/anaconda/anaconda3/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/data/krf/anaconda/anaconda3/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/data/krf/anaconda/anaconda3/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/data/krf/model/pytorch-retinanet/mydataloader.py\", line 109, in __getitem__\n",
      "    sample = self.transform(sample)\n",
      "  File \"/data/krf/anaconda/anaconda3/lib/python3.5/site-packages/torchvision-0.2.1-py3.5.egg/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "  File \"/data/krf/model/pytorch-retinanet/dataloader.py\", line 412, in __call__\n",
      "    return {'img':((image.astype(np.float32)-self.mean)/self.std), 'annot': annots}\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2ecd491fa41d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                 \u001b[0mclassification_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregression_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretinanets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'annot'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m                 \u001b[0mclassification_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mregression_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregression_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/krf/anaconda/anaconda3/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/krf/anaconda/anaconda3/lib/python3.5/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/krf/anaconda/anaconda3/lib/python3.5/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mreplicate\u001b[0;34m(self, module, device_ids)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/krf/anaconda/anaconda3/lib/python3.5/site-packages/torch/nn/parallel/replicate.py\u001b[0m in \u001b[0;36mreplicate\u001b[0;34m(network, devices, detach)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mparam_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mparam_copies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBroadcast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         param_copies = [param_copies[i:i + len(params)]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "count = [0,0,0,0]\n",
    "import traceback\n",
    "for epoch_num in range(EPOCHS):\n",
    "\n",
    "    for i in range(4):\n",
    "        retinanets[i].train()\n",
    "        retinanets[i].module.freeze_bn()\n",
    "        epoch_loss = []\n",
    "        \n",
    "        for iter_num, data in enumerate(dataloader_train[i]):\n",
    "            try:\n",
    "                optimizer[i].zero_grad()\n",
    "\n",
    "                classification_loss, regression_loss = retinanets[i]([Variable(data['img'].cuda().float()), Variable(data['annot'].cuda())])\n",
    "                classification_loss = classification_loss.mean()\n",
    "                regression_loss = regression_loss.mean()\n",
    "\n",
    "                loss = classification_loss + regression_loss\n",
    "\n",
    "                if bool(loss == 0):\n",
    "                    continue\n",
    "                #反向传播？\n",
    "                loss.backward()\n",
    "\n",
    "                #这是干嘛？？TODO\n",
    "                torch.nn.utils.clip_grad_norm_(retinanets[i].parameters(), 0.1)\n",
    "\n",
    "                #这?TODO\n",
    "                optimizer[i].step()\n",
    "\n",
    "                loss_hist[i].append(float(loss))\n",
    "\n",
    "                epoch_loss.append(float(loss))\n",
    "\n",
    "                print('Epoch: {} | Iteration: {} | Classification loss: {:1.5f} | Regression loss: {:1.5f} | Running loss: {:1.5f}'.format(epoch_num, iter_num, float(classification_loss), float(regression_loss), np.mean(loss_hist[i])))\n",
    "                vis.line(X=torch.Tensor([count[i]]), Y=torch.Tensor([np.mean(loss_hist[i])]), win='train loss '+str(i), update='append' ,opts={'title':'train loss '+str(i)})\n",
    "                count[i] += 1\n",
    "                vis.save(['retinanet_seresnext101'])\n",
    "\n",
    "                del classification_loss\n",
    "                del regression_loss\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue\n",
    "\n",
    "\n",
    "        print(\"Evaluating dataset\")\n",
    "    #     retinanet.eval()\n",
    "    #     for index,data in enumerate(dataloader_val):\n",
    "    #         #data = dataset[index]\n",
    "    #         scale = data['scale']\n",
    "    #         # run network\n",
    "    #         #scores, labels, boxes = retinanet(data['img'].permute(2, 0, 1).cuda().float().unsqueeze(dim=0))\n",
    "    #         print(Variable(data['img'].cuda()))\n",
    "    #         scores, labels, boxes = retinanet(Variable(data['img'].cuda()))\n",
    "    #         #mAP = csv_eval.evaluate(dataset_val,retinanet)\n",
    "        try:\n",
    "            mAP = csv_eval.evaluate(dataset_val[i],retinanets[i])\n",
    "            vis.line(X=torch.Tensor([epoch_num]), Y=torch.Tensor([mAP[0][0]]), win='val mAP '+str(i), update='append' ,opts={'title':'mAP val '+str(i)})\n",
    "            vis.save(['retinanet_seresnext101'])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print( 'traceback.print_exc():', traceback.print_exc())\n",
    "            continue\n",
    "        #这一步也看不懂？？TODO \n",
    "        scheduler[i].step(np.mean(epoch_loss))\n",
    "\n",
    "        torch.save(retinanets[i].module, 'weights_stage1/{}_seresnext101_{}.pt'.format(i, epoch_num))\n",
    "    #     torch.save(retinanet.module, '{}_retinanet_{}.pt'.format(parser.dataset, epoch_num))\n",
    "\n",
    "for i in range(4):\n",
    "    retinanets[i].eval()\n",
    "    torch.save(retinanets[i], 'weights_stage1/{}_model_final_seresnext101.pt'.format(i))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
